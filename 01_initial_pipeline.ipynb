{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display, Image as IPImage\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Retrieve captions + images for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata for training data\n",
    "json_file = os.path.join(\"2024_dataset\", \"train_downloaded.json\")\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ID: 11mk4th\n",
      "Caption: Most probably it is a case of Milia. A milium is a small cyst containing keratin (the skin protein). Milia do not need to be treated unless they are a cause for concern for the patient. They often clear up by themselves within a few months. Where possible, further trauma should be minimized to reduce the development of new lesions. The lesion may be de-roofed using a sterile needle or blade and the contents squeezed or pricked out.\n",
      "They may be destroyed using diathermy and curettage, or cryotherapy.\n"
     ]
    }
   ],
   "source": [
    "# Access image and caption data for first entry\n",
    "if data:\n",
    "    first_entry = data[0]\n",
    "    image_id = first_entry[\"encounter_id\"]\n",
    "    caption = first_entry[\"responses\"][0][\"content_en\"]\n",
    "    print(f\"Image ID: {image_id}\")\n",
    "    print(f\"Caption: {caption}\")\n",
    "else:\n",
    "    print(\"The dataset is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "images_dir = os.path.join(\"2024_dataset\", \"images\", \"train\")\n",
    "script_path = os.path.join(\"2024_dataset\", \"download_data.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024_dataset\\images\\train\\ih99w9.jpg</td>\n",
       "      <td>Most probably it is a case of inflamed pimple,...</td>\n",
       "      <td>I had this mole that appeared under my eye abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024_dataset\\images\\train\\11n62qx.jpg</td>\n",
       "      <td>Most probably it is a case of solar lentigo, a...</td>\n",
       "      <td>Spot in my hairline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024_dataset\\images\\train\\vk578x.jpg</td>\n",
       "      <td>Most propably it is a case of a cyst in the gr...</td>\n",
       "      <td>Can someone help me ID this random bump? Today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024_dataset\\images\\train\\123bko0.jpg</td>\n",
       "      <td>It is a case of common wart. This noncancerous...</td>\n",
       "      <td>Rough bump/spot on the side of finger? What ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024_dataset\\images\\train\\11m0l9c.jpg</td>\n",
       "      <td>Most probably it is a case of deep coarse wrin...</td>\n",
       "      <td>Puffy line on face any suggestions?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image_path  \\\n",
       "0   2024_dataset\\images\\train\\ih99w9.jpg   \n",
       "1  2024_dataset\\images\\train\\11n62qx.jpg   \n",
       "2   2024_dataset\\images\\train\\vk578x.jpg   \n",
       "3  2024_dataset\\images\\train\\123bko0.jpg   \n",
       "4  2024_dataset\\images\\train\\11m0l9c.jpg   \n",
       "\n",
       "                                             caption  \\\n",
       "0  Most probably it is a case of inflamed pimple,...   \n",
       "1  Most probably it is a case of solar lentigo, a...   \n",
       "2  Most propably it is a case of a cyst in the gr...   \n",
       "3  It is a case of common wart. This noncancerous...   \n",
       "4  Most probably it is a case of deep coarse wrin...   \n",
       "\n",
       "                                               query  \n",
       "0  I had this mole that appeared under my eye abo...  \n",
       "1                                Spot in my hairline  \n",
       "2  Can someone help me ID this random bump? Today...  \n",
       "3  Rough bump/spot on the side of finger? What ex...  \n",
       "4                Puffy line on face any suggestions?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine image paths with captions for both .jpg and .png formats\n",
    "data_combined = []\n",
    "\n",
    "for entry in data:\n",
    "    jpg_path = os.path.join(images_dir, f\"{entry['encounter_id']}.jpg\")\n",
    "    png_path = os.path.join(images_dir, f\"{entry['encounter_id']}.png\")\n",
    "\n",
    "    # Check which image format exists\n",
    "    if os.path.exists(jpg_path):\n",
    "        image_path = jpg_path\n",
    "    elif os.path.exists(png_path):\n",
    "        image_path = png_path\n",
    "    else:\n",
    "        continue  # Skip if neither format exists\n",
    "\n",
    "    data_combined.append({\n",
    "        \"image_path\": image_path,\n",
    "        \"caption\": entry[\"responses\"][0][\"content_en\"],  # This is the correct answer caption\n",
    "        \"query\": entry[\"query_title_en\"]\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data_combined)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first image and its caption\n",
    "first_row = df.iloc[0]\n",
    "image_path = first_row[\"image_path\"]\n",
    "caption = first_row[\"caption\"]\n",
    "query = first_row[\"query\"]\n",
    "\n",
    "# Open and display the image\n",
    "img = Image.open(image_path)\n",
    "img.thumbnail((300, 300))  # Resize to a maximum width and height of 300 pixels\n",
    "display(img)\n",
    "\n",
    "# Print the caption\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Caption: {caption}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Pass it through an initial baseline architecture\n",
    "\n",
    "<img src=\"image.png\" alt=\"image.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load environment variables and configure Gemini\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: is there a med-gemini we can use? https://research.google/blog/advancing-medical-ai-with-med-gemini/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a function to process the image with Gemini\n",
    "def process_image_with_gemini(image_path, model):\n",
    "    image_prompt = f\"\"\"\n",
    "    Describe the following image in detail for a medical context.\n",
    "    Provide a comprehensive description including any visible abnormalities, patterns, or other notable observations.\n",
    "    Output the description in plain text without any additional formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content([image_prompt, Image.open(image_path)])\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_description = process_image_with_gemini(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the query, caption, and Gemini description\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Caption: {caption}\")\n",
    "print(f\"Gemini Description: {gemini_description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Combine Gemini's output with the query and generate a response\n",
    "def generate_response(query, image_description, model):\n",
    "    response_prompt = f\"\"\"\n",
    "    Based on the following query and image description, provide a detailed and helpful medical response:\n",
    "\n",
    "    Query: {query}\n",
    "    Image Description: {image_description}\n",
    "\n",
    "    Output the response in plain text without any additional formatting.\n",
    "    \"\"\"\n",
    "    response = model.generate_content(response_prompt)\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_response = generate_response(query, gemini_description, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the query, caption, Gemini description, and generated response\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Caption: {caption}\")\n",
    "print(f\"Gemini Description: {gemini_description}\")\n",
    "print(f\"Generated Response: {generated_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: How does the above process compare to simply just having a single prompt where both the image and query are provided to retrieve image description? It seems less confident in its understanding of what it could be from these outputs. What else can we do to improve the quality of the repsonse in addition to changing the process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.5: Filter the dataset for valid image paths\n",
    "def filter_valid_entries(data, images_dir):\n",
    "    valid_entries = []\n",
    "    for entry in data:\n",
    "        image_path = os.path.normpath(os.path.join(images_dir, f\"{entry['encounter_id']}.jpg\"))\n",
    "        if os.path.exists(image_path):  # Check if the image file exists\n",
    "            valid_entries.append(entry)\n",
    "        else:\n",
    "            print(f\"Skipping entry with missing image: {entry['encounter_id']}\")\n",
    "    return valid_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Workflow to process an image, query, and caption\n",
    "def process_entry(entry, images_dir, model):\n",
    "    # Construct the full image path\n",
    "    image_path = os.path.normpath(os.path.join(images_dir, f\"{entry['encounter_id']}.jpg\"))\n",
    "    \n",
    "    # Debugging: Print the constructed image path\n",
    "    print(f\"Constructed image path: {image_path}\")\n",
    "    \n",
    "    # Check if the image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image does not exist: {image_path}\")\n",
    "        return None  # Skip entries without an image\n",
    "\n",
    "    # Extract query and caption\n",
    "    query = entry.get(\"query_title_en\", \"No query provided.\")\n",
    "    original_caption = entry[\"responses\"][0][\"content_en\"]\n",
    "\n",
    "    # Process the image with Gemini\n",
    "    image_description = process_image_with_gemini(image_path, model)\n",
    "\n",
    "    # Generate a response\n",
    "    response = generate_response(query, image_description, model)\n",
    "\n",
    "    # Return the combined data\n",
    "    return {\n",
    "        \"image_path\": image_path,\n",
    "        \"query\": query,\n",
    "        \"original_caption\": original_caption,\n",
    "        \"image_description\": image_description,\n",
    "        \"response\": response,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data\n",
    "json_file = os.path.join(\"2024_dataset\", \"train_downloaded.json\")\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Filter the dataset to only include entries with valid image paths\n",
    "filtered_data = filter_valid_entries(data, images_dir)\n",
    "\n",
    "# Process the filtered dataset\n",
    "if filtered_data:\n",
    "    # Example: Process only the first valid entry\n",
    "    first_entry = filtered_data[0]\n",
    "    processed_entry = process_entry(first_entry, images_dir, model)\n",
    "\n",
    "    # Debugging: Check the processed entry\n",
    "    if processed_entry:\n",
    "        print(\"Processed Entry:\")\n",
    "        print(processed_entry)\n",
    "    else:\n",
    "        print(\"Processing failed for the first valid entry.\")\n",
    "else:\n",
    "    print(\"No valid entries with images were found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: there seem to be guardrails in place - how to prompt engineer this so the output is as meaningful for the patient + similiar to the conference results needed (aka without the guardrails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Example Data Processing for all entires in the dataset\n",
    "def process_dataset(data, images_dir, model):\n",
    "    results = []\n",
    "    for entry in data:\n",
    "        result = process_entry(entry, images_dir, model)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code when we are ready to process the entire dataset\n",
    "\n",
    "# # Load the dataset\n",
    "# with open(os.path.join('2024_dataset', 'train_downloaded.json'), 'r', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Define the images directory\n",
    "# images_dir = os.path.join(\"2024_dataset\", \"images\", \"train\")\n",
    "\n",
    "# # Configure the Gemini model\n",
    "# load_dotenv()\n",
    "# api_key = os.getenv('API_KEY')\n",
    "# genai.configure(api_key=api_key)\n",
    "# model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# # Filter valid entries (optional but recommended to avoid missing images)\n",
    "# data_filtered = [entry for entry in data if os.path.exists(os.path.join(images_dir, f\"{entry['encounter_id']}.jpg\"))]\n",
    "\n",
    "# # Process the dataset\n",
    "# processed_df = process_dataset(data_filtered, images_dir, model)\n",
    "\n",
    "# # Inspect the output\n",
    "# print(processed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Display an example in the dataset with side-by-side comparison\n",
    "def display_example(row):\n",
    "    # Load and display the image\n",
    "    img = Image.open(row[\"image_path\"])\n",
    "    img.thumbnail((300, 300))\n",
    "    display(img)\n",
    "\n",
    "    # Print the details\n",
    "    print(f\"Query: {row['query']}\\n\")\n",
    "    print(f\"Original Caption: {row['original_caption']}\\n\")\n",
    "    print(f\"Gemini Image Description: {row['image_description']}\\n\")\n",
    "    print(f\"Generated Response: {row['response']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code when we are ready to process the entire dataset\n",
    "\n",
    "# # Ensure the DataFrame has been processed\n",
    "# processed_df = process_dataset(filtered_data, images_dir, model)\n",
    "\n",
    "# # Check if the DataFrame is not empty\n",
    "# if not processed_df.empty:\n",
    "#     # Display the first example in the dataset\n",
    "#     display_example(processed_df.iloc[0])\n",
    "# else:\n",
    "#     print(\"No valid entries found in the dataset to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTIONS: How can we add in the following: \n",
    "- Medical chain-of-thought - see https://arxiv.org/abs/2412.13736v1\n",
    "- Figure out to map generative text to multiple choice \n",
    "- Test out augmenting the queries? or image descriptions? with ShareCaptioner\n",
    "- Is there a way to extract high- and low-level image features? Taking inspo from Flickr30k dataset..\n",
    "- What would LLM finetuning look like here? Can we finetune multiple LLMs (region specific) and employ weight-merging or multitask learning?\n",
    "- Could we leverage multimodal explainability here to provide transparency in model's reasoning? https://jayneelparekh.github.io/LMM_Concept_Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
