{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b11721ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import base64\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "import json\n",
    "import io\n",
    "import base64\n",
    "import traceback\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "593bbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_aggregated_files(output_dir):\n",
    "    # Get all aggregated prediction files\n",
    "    pattern = os.path.join(output_dir, \"aggregated_predictions_*.csv\")\n",
    "    print(f\"Searching for files with pattern: {pattern}\")\n",
    "    \n",
    "    agg_files = glob.glob(pattern)\n",
    "    print(f\"Found {len(agg_files)} aggregated prediction files\")\n",
    "    \n",
    "    if len(agg_files) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Dictionary to keep track of latest file for each model\n",
    "    latest_files = {}\n",
    "    \n",
    "    # Process each file\n",
    "    for file_path in agg_files:\n",
    "        # Extract file name\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        # Extract model name (between \"aggregated_predictions_\" and \"_base_\")\n",
    "        parts = file_name.split(\"_base_\")\n",
    "        if len(parts) != 2:\n",
    "            print(f\"Warning: Unexpected filename format: {file_name}\")\n",
    "            continue\n",
    "        \n",
    "        model_part = parts[0].replace(\"aggregated_predictions_\", \"\")\n",
    "        model_name = model_part\n",
    "        \n",
    "        # Extract timestamp (second numeric part after _base_)\n",
    "        timestamps = re.findall(r'(\\d+)', parts[1])\n",
    "        if len(timestamps) < 2:\n",
    "            print(f\"Warning: Could not find timestamps in {file_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Use the second timestamp (should be the file timestamp)\n",
    "        timestamp = int(timestamps[1])\n",
    "        \n",
    "        print(f\"Found model: {model_name}, timestamp: {timestamp}\")\n",
    "        \n",
    "        # If this model isn't in our dictionary yet, or this file is newer\n",
    "        if model_name not in latest_files or timestamp > latest_files[model_name]['timestamp']:\n",
    "            latest_files[model_name] = {\n",
    "                'file_path': file_path,\n",
    "                'timestamp': timestamp\n",
    "            }\n",
    "    \n",
    "    # Print the selected files\n",
    "    print(\"\\nSelected latest file for each model:\")\n",
    "    for model, info in latest_files.items():\n",
    "        print(f\"  {model}: {os.path.basename(info['file_path'])}\")\n",
    "    \n",
    "    # Return just the file paths\n",
    "    return [info['file_path'] for model, info in latest_files.items()]\n",
    "\n",
    "def load_all_model_predictions(output_dir):\n",
    "    latest_files = get_latest_aggregated_files(output_dir)\n",
    "    \n",
    "    if not latest_files:\n",
    "        print(\"No aggregated prediction files found. Cannot proceed.\")\n",
    "        return {}\n",
    "    \n",
    "    # Dictionary to store dataframes by model name\n",
    "    model_predictions = {}\n",
    "    \n",
    "    # Load each file into a dataframe\n",
    "    for file_path in latest_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        # Extract model name from filename\n",
    "        parts = file_name.split(\"_base_\")\n",
    "        if len(parts) != 2:\n",
    "            print(f\"Warning: Unexpected filename format: {file_name}\")\n",
    "            continue\n",
    "            \n",
    "        model_name = parts[0].replace(\"aggregated_predictions_\", \"\")\n",
    "        \n",
    "        # Load the dataframe\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Add a column identifying which model this came from\n",
    "            df['model_name'] = model_name\n",
    "            \n",
    "            # Store in dictionary\n",
    "            model_predictions[model_name] = df\n",
    "            \n",
    "            print(f\"Successfully loaded {model_name} predictions with {len(df)} rows\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len(model_predictions)} model prediction sets\")\n",
    "    return model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d40674b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for files with pattern: /storage/scratch1/2/kthakrar3/mediqa-magic-v2/outputs/outputs-akshay-2/outputs/aggregated_predictions_*.csv\n",
      "Found 12 aggregated prediction files\n",
      "Found model: gemma-3-12b-it, timestamp: 115333\n",
      "Found model: gemma-3-12b-it, timestamp: 151119\n",
      "Found model: Qwen2-VL-7B-Instruct, timestamp: 120954\n",
      "Found model: Qwen2-VL-2B-Instruct, timestamp: 124256\n",
      "Found model: gemma-3-4b-it, timestamp: 151631\n",
      "Found model: Llama-3.2-11B-Vision-Instruct, timestamp: 111944\n",
      "Found model: Llama-3.2-11B-Vision-Instruct, timestamp: 124737\n",
      "Found model: Qwen2-VL-2B-Instruct, timestamp: 112949\n",
      "Found model: Qwen2.5-VL-7B-Instruct, timestamp: 134915\n",
      "Found model: Qwen2.5-VL-3B-Instruct, timestamp: 132244\n",
      "Found model: Qwen2-VL-7B-Instruct, timestamp: 124322\n",
      "Found model: Qwen2.5-VL-7B-Instruct, timestamp: 140634\n",
      "\n",
      "Selected latest file for each model:\n",
      "  gemma-3-12b-it: aggregated_predictions_gemma-3-12b-it_base_20250428_151119_20250428_151119.csv\n",
      "  Qwen2-VL-7B-Instruct: aggregated_predictions_Qwen2-VL-7B-Instruct_base_20250428_124322_20250428_124322.csv\n",
      "  Qwen2-VL-2B-Instruct: aggregated_predictions_Qwen2-VL-2B-Instruct_base_20250428_124256_20250428_124256.csv\n",
      "  gemma-3-4b-it: aggregated_predictions_gemma-3-4b-it_base_20250428_151631_20250428_151631.csv\n",
      "  Llama-3.2-11B-Vision-Instruct: aggregated_predictions_Llama-3.2-11B-Vision-Instruct_base_20250428_124737_20250428_124737.csv\n",
      "  Qwen2.5-VL-7B-Instruct: aggregated_predictions_Qwen2.5-VL-7B-Instruct_base_20250428_140634_20250428_140634.csv\n",
      "  Qwen2.5-VL-3B-Instruct: aggregated_predictions_Qwen2.5-VL-3B-Instruct_base_20250428_132244_20250428_132244.csv\n",
      "Successfully loaded gemma-3-12b-it predictions with 504 rows\n",
      "Successfully loaded Qwen2-VL-7B-Instruct predictions with 504 rows\n",
      "Successfully loaded Qwen2-VL-2B-Instruct predictions with 504 rows\n",
      "Successfully loaded gemma-3-4b-it predictions with 504 rows\n",
      "Successfully loaded Llama-3.2-11B-Vision-Instruct predictions with 504 rows\n",
      "Successfully loaded Qwen2.5-VL-7B-Instruct predictions with 504 rows\n",
      "Successfully loaded Qwen2.5-VL-3B-Instruct predictions with 504 rows\n",
      "Loaded 7 model prediction sets\n",
      "\n",
      "Loaded models:\n",
      "  gemma-3-12b-it: 504 rows\n",
      "  Qwen2-VL-7B-Instruct: 504 rows\n",
      "  Qwen2-VL-2B-Instruct: 504 rows\n",
      "  gemma-3-4b-it: 504 rows\n",
      "  Llama-3.2-11B-Vision-Instruct: 504 rows\n",
      "  Qwen2.5-VL-7B-Instruct: 504 rows\n",
      "  Qwen2.5-VL-3B-Instruct: 504 rows\n",
      "\n",
      "Combined dataframe has 3528 rows\n",
      "Number of unique encounter-question pairs: 504\n",
      "\n",
      "Example of data structure:\n",
      "Columns: ['encounter_id', 'base_qid', 'image_ids', 'unique_predictions', 'combined_prediction', 'all_raw_predictions', 'all_sorted_predictions', 'options_en', 'model_name']\n",
      "\n",
      "Sample data for encounter ENC00852, question CQID010:\n",
      "\n",
      "  Model: gemma-3-12b-it\n",
      "  Combined prediction: nan\n",
      "\n",
      "  Model: Qwen2-VL-7B-Instruct\n",
      "  Combined prediction: limited area\n",
      "\n",
      "  Model: Qwen2-VL-2B-Instruct\n",
      "  Combined prediction: limited area\n",
      "\n",
      "  Model: gemma-3-4b-it\n",
      "  Combined prediction: limited area\n",
      "\n",
      "  Model: Llama-3.2-11B-Vision-Instruct\n",
      "  Combined prediction: not mentioned\n",
      "\n",
      "  Model: Qwen2.5-VL-7B-Instruct\n",
      "  Combined prediction: widespread\n",
      "\n",
      "  Model: Qwen2.5-VL-3B-Instruct\n",
      "  Combined prediction: limited area\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(os.getcwd(), \"outputs\", \"outputs-akshay-2\", \"outputs\")\n",
    "model_predictions = load_all_model_predictions(output_dir)\n",
    "\n",
    "if model_predictions:\n",
    "    # Show which models we loaded\n",
    "    print(\"\\nLoaded models:\")\n",
    "    for model_name, df in model_predictions.items():\n",
    "        print(f\"  {model_name}: {len(df)} rows\")\n",
    "    \n",
    "    # Create a combined dataframe with all model predictions\n",
    "    all_models_df = pd.concat(model_predictions.values(), ignore_index=True)\n",
    "    print(f\"\\nCombined dataframe has {len(all_models_df)} rows\")\n",
    "    \n",
    "    # Create an encounter-level dataframe\n",
    "    encounter_groups = all_models_df.groupby(['encounter_id', 'base_qid'])\n",
    "    print(f\"Number of unique encounter-question pairs: {len(encounter_groups)}\")\n",
    "    \n",
    "    # Sample of the data structure\n",
    "    print(\"\\nExample of data structure:\")\n",
    "    print(f\"Columns: {all_models_df.columns.tolist()}\")\n",
    "    \n",
    "    # First encounter-question pair as example\n",
    "    first_group = next(iter(encounter_groups))\n",
    "    print(f\"\\nSample data for encounter {first_group[0][0]}, question {first_group[0][1]}:\")\n",
    "    for model_name in model_predictions.keys():\n",
    "        model_rows = first_group[1][first_group[1]['model_name'] == model_name]\n",
    "        if not model_rows.empty:\n",
    "            row = model_rows.iloc[0]\n",
    "            print(f\"\\n  Model: {model_name}\")\n",
    "            print(f\"  Combined prediction: {row['combined_prediction']}\")\n",
    "else:\n",
    "    print(\"No model predictions were loaded. Please check the directory path and file patterns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9facd24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>base_qid</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>unique_predictions</th>\n",
       "      <th>combined_prediction</th>\n",
       "      <th>all_raw_predictions</th>\n",
       "      <th>all_sorted_predictions</th>\n",
       "      <th>options_en</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENC00852</td>\n",
       "      <td>CQID010</td>\n",
       "      <td>['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', '']</td>\n",
       "      <td>[('', 2)]</td>\n",
       "      <td>['single spot', 'limited area', 'widespread', ...</td>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENC00852</td>\n",
       "      <td>CQID011</td>\n",
       "      <td>['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...</td>\n",
       "      <td>['face', 'upper extremities', 'back of the hand']</td>\n",
       "      <td>face, upper extremities, back of the hand</td>\n",
       "      <td>['back of the hand', 'face', 'upper extremitie...</td>\n",
       "      <td>[('face', 2), ('upper extremities', 2), ('back...</td>\n",
       "      <td>['head', 'neck', 'upper extremities', 'lower e...</td>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENC00852</td>\n",
       "      <td>CQID012</td>\n",
       "      <td>['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...</td>\n",
       "      <td>['larger area']</td>\n",
       "      <td>larger area</td>\n",
       "      <td>['larger area', 'larger area']</td>\n",
       "      <td>[('larger area', 2)]</td>\n",
       "      <td>['size of thumb nail', 'size of palm', 'larger...</td>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENC00852</td>\n",
       "      <td>CQID015</td>\n",
       "      <td>['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...</td>\n",
       "      <td>['within months']</td>\n",
       "      <td>within months</td>\n",
       "      <td>['within months', 'within months']</td>\n",
       "      <td>[('within months', 2)]</td>\n",
       "      <td>['within hours', 'within days', 'within weeks'...</td>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENC00852</td>\n",
       "      <td>CQID020</td>\n",
       "      <td>['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...</td>\n",
       "      <td>['flat', 'thin or close to the surface']</td>\n",
       "      <td>flat, thin or close to the surface</td>\n",
       "      <td>['flat', 'thin or close to the surface', 'flat']</td>\n",
       "      <td>[('flat', 2), ('thin or close to the surface',...</td>\n",
       "      <td>['raised or bumpy', 'flat', 'skin loss or sunk...</td>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  encounter_id base_qid                                          image_ids  \\\n",
       "0     ENC00852  CQID010  ['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...   \n",
       "1     ENC00852  CQID011  ['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...   \n",
       "2     ENC00852  CQID012  ['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...   \n",
       "3     ENC00852  CQID015  ['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...   \n",
       "4     ENC00852  CQID020  ['IMG_ENC00852_00001.jpg', 'IMG_ENC00852_00002...   \n",
       "\n",
       "                                  unique_predictions  \\\n",
       "0                                               ['']   \n",
       "1  ['face', 'upper extremities', 'back of the hand']   \n",
       "2                                    ['larger area']   \n",
       "3                                  ['within months']   \n",
       "4           ['flat', 'thin or close to the surface']   \n",
       "\n",
       "                         combined_prediction  \\\n",
       "0                                        NaN   \n",
       "1  face, upper extremities, back of the hand   \n",
       "2                                larger area   \n",
       "3                              within months   \n",
       "4         flat, thin or close to the surface   \n",
       "\n",
       "                                 all_raw_predictions  \\\n",
       "0                                           ['', '']   \n",
       "1  ['back of the hand', 'face', 'upper extremitie...   \n",
       "2                     ['larger area', 'larger area']   \n",
       "3                 ['within months', 'within months']   \n",
       "4   ['flat', 'thin or close to the surface', 'flat']   \n",
       "\n",
       "                              all_sorted_predictions  \\\n",
       "0                                          [('', 2)]   \n",
       "1  [('face', 2), ('upper extremities', 2), ('back...   \n",
       "2                               [('larger area', 2)]   \n",
       "3                             [('within months', 2)]   \n",
       "4  [('flat', 2), ('thin or close to the surface',...   \n",
       "\n",
       "                                          options_en      model_name  \n",
       "0  ['single spot', 'limited area', 'widespread', ...  gemma-3-12b-it  \n",
       "1  ['head', 'neck', 'upper extremities', 'lower e...  gemma-3-12b-it  \n",
       "2  ['size of thumb nail', 'size of palm', 'larger...  gemma-3-12b-it  \n",
       "3  ['within hours', 'within days', 'within weeks'...  gemma-3-12b-it  \n",
       "4  ['raised or bumpy', 'flat', 'skin loss or sunk...  gemma-3-12b-it  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "254a6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_dataset(val_dataset_path):\n",
    "    \"\"\"\n",
    "    Load the validation dataset while preserving all images and ground truth answers\n",
    "    for each encounter-question pair.\n",
    "    \"\"\"\n",
    "    print(f\"Loading validation dataset from {val_dataset_path}\")\n",
    "    val_df = pd.read_csv(val_dataset_path)\n",
    "    print(f\"Loaded validation dataset with {len(val_df)} rows\")\n",
    "    \n",
    "    # Process and clean the validation dataset\n",
    "    val_df = process_validation_dataset(val_df)\n",
    "    \n",
    "    # Create a dictionary to store all data grouped by encounter and question\n",
    "    encounter_question_data = defaultdict(lambda: {\n",
    "        'images': [],\n",
    "        'data': None,\n",
    "        'ground_truth': None\n",
    "    })\n",
    "    \n",
    "    # Process each row in the validation dataset\n",
    "    for _, row in val_df.iterrows():\n",
    "        encounter_id = row['encounter_id']\n",
    "        base_qid = row['base_qid']\n",
    "        key = (encounter_id, base_qid)\n",
    "        \n",
    "        # Add image path to the images list\n",
    "        if 'image_path' in row and row['image_path']:\n",
    "            encounter_question_data[key]['images'].append(row['image_path'])\n",
    "        elif 'image_id' in row and row['image_id']:\n",
    "            # If only image_id is available, construct the path\n",
    "            image_dir = os.path.join(os.getcwd(), \"2025_dataset\", \"valid\", \"images_valid\")\n",
    "            image_path = os.path.join(image_dir, row['image_id'])\n",
    "            encounter_question_data[key]['images'].append(image_path)\n",
    "        \n",
    "        # Store row data if not already stored\n",
    "        if encounter_question_data[key]['data'] is None:\n",
    "            encounter_question_data[key]['data'] = row.to_dict()\n",
    "            \n",
    "        # Process ground truth answers if available\n",
    "        if 'valid_answers' in row and row['valid_answers'] and encounter_question_data[key]['ground_truth'] is None:\n",
    "            # Extract ground truth answers\n",
    "            raw_answers = row['valid_answers']\n",
    "            \n",
    "            # Convert string representation to list if needed\n",
    "            if isinstance(raw_answers, str):\n",
    "                try:\n",
    "                    raw_answers = ast.literal_eval(raw_answers)\n",
    "                except:\n",
    "                    # If eval fails, handle as comma-separated string\n",
    "                    if ',' in raw_answers:\n",
    "                        raw_answers = [ans.strip() for ans in raw_answers.split(',')]\n",
    "                    else:\n",
    "                        raw_answers = [raw_answers.strip()]\n",
    "            \n",
    "            # Clean answers similar to how model predictions are cleaned\n",
    "            cleaned_answers = []\n",
    "            for ans in raw_answers:\n",
    "                if isinstance(ans, str):\n",
    "                    # Remove any quotes and trailing/leading spaces\n",
    "                    cleaned_ans = ans.strip(\"'\\\" \")\n",
    "                    # Remove \"(please specify)\"\n",
    "                    cleaned_ans = cleaned_ans.replace(\" (please specify)\", \"\")\n",
    "                    cleaned_answers.append(cleaned_ans)\n",
    "                else:\n",
    "                    cleaned_answers.append(str(ans).strip(\"'\\\" \"))\n",
    "            \n",
    "            # Create formatted answer string\n",
    "            combined_answer = \", \".join(cleaned_answers)\n",
    "            \n",
    "            # Store ground truth data\n",
    "            encounter_question_data[key]['ground_truth'] = {\n",
    "                'raw_answers': raw_answers,\n",
    "                'cleaned_answers': cleaned_answers,\n",
    "                'combined_answer': combined_answer\n",
    "            }\n",
    "    \n",
    "    print(f\"Created grouped validation dataset with {len(encounter_question_data)} unique encounter-question pairs\")\n",
    "    \n",
    "    # Convert to a list of dictionaries for easier handling\n",
    "    grouped_data = []\n",
    "    for (encounter_id, base_qid), data in encounter_question_data.items():\n",
    "        entry = data['data'].copy()\n",
    "        entry['all_images'] = data['images']\n",
    "        entry['ground_truth'] = data['ground_truth']\n",
    "        entry['encounter_id'] = encounter_id\n",
    "        entry['base_qid'] = base_qid\n",
    "        grouped_data.append(entry)\n",
    "    \n",
    "    return pd.DataFrame(grouped_data)\n",
    "\n",
    "def safe_convert_options(options_str):\n",
    "    \"\"\"Safely convert a string representation of a list to an actual list.\"\"\"\n",
    "    if not isinstance(options_str, str):\n",
    "        return options_str\n",
    "        \n",
    "    try:\n",
    "        return ast.literal_eval(options_str)\n",
    "    except (SyntaxError, ValueError):\n",
    "        if options_str.startswith('[') and options_str.endswith(']'):\n",
    "            return [opt.strip().strip(\"'\\\"\") for opt in options_str[1:-1].split(',')]\n",
    "        elif ',' in options_str:\n",
    "            return [opt.strip() for opt in options_str.split(',')]\n",
    "        else:\n",
    "            return [options_str]\n",
    "\n",
    "def process_validation_dataset(val_df):\n",
    "    \"\"\"Process and clean the validation dataset.\"\"\"\n",
    "    # Convert string representations to actual Python objects\n",
    "    if 'options_en' in val_df.columns:\n",
    "        val_df['options_en'] = val_df['options_en'].apply(safe_convert_options)\n",
    "        \n",
    "        # Clean options by removing \"(please specify)\" phrases\n",
    "        def clean_options(options):\n",
    "            if not isinstance(options, list):\n",
    "                return options\n",
    "                \n",
    "            cleaned_options = []\n",
    "            for opt in options:\n",
    "                if isinstance(opt, str):\n",
    "                    cleaned_opt = opt.strip(\"'\\\" \").replace(\" (please specify)\", \"\")\n",
    "                    cleaned_options.append(cleaned_opt)\n",
    "                else:\n",
    "                    cleaned_options.append(str(opt).strip(\"'\\\" \"))\n",
    "            return cleaned_options\n",
    "            \n",
    "        val_df['options_en_cleaned'] = val_df['options_en'].apply(clean_options)\n",
    "    \n",
    "    # Clean question text\n",
    "    if 'question_text' in val_df.columns:\n",
    "        # Remove \"Please specify which affected area for each selection.\" from CQID012\n",
    "        val_df['question_text_cleaned'] = val_df['question_text'].apply(\n",
    "            lambda q: q.replace(\" Please specify which affected area for each selection.\", \"\") \n",
    "                      if isinstance(q, str) and \"Please specify which affected area for each selection\" in q \n",
    "                      else q\n",
    "        )\n",
    "        \n",
    "        # Remove leading numbers like \"1 \" from the beginning of questions\n",
    "        val_df['question_text_cleaned'] = val_df['question_text_cleaned'].apply(\n",
    "            lambda q: re.sub(r'^\\d+\\s+', '', q) if isinstance(q, str) else q\n",
    "        )\n",
    "    \n",
    "    # Extract base_qid if it doesn't exist\n",
    "    if 'base_qid' not in val_df.columns and 'qid' in val_df.columns:\n",
    "        val_df['base_qid'] = val_df['qid'].apply(\n",
    "            lambda q: q.split('-')[0] if isinstance(q, str) and '-' in q else q\n",
    "        )\n",
    "    \n",
    "    return val_df\n",
    "\n",
    "def create_query_context(row):\n",
    "    \"\"\"Create query context from validation data similar to the inference process.\"\"\"\n",
    "    # Get cleaned question text\n",
    "    question = row.get('question_text_cleaned', row.get('question_text', 'What do you see in this image?'))\n",
    "    \n",
    "    # Create metadata string\n",
    "    metadata = \"\"\n",
    "    if 'question_type_en' in row:\n",
    "        metadata += f\"Type: {row['question_type_en']}\"\n",
    "        \n",
    "    if 'question_category_en' in row:\n",
    "        metadata += f\", Category: {row['question_category_en']}\"\n",
    "    \n",
    "    # Get clinical context from query title and content\n",
    "    query_title = row.get('query_title_en', '')\n",
    "    query_content = row.get('query_content_en', '')\n",
    "    \n",
    "    # Create the clinical context section\n",
    "    clinical_context = \"\"\n",
    "    if query_title or query_content:\n",
    "        clinical_context += \"Background Clinical Information (to help with your analysis):\\n\"\n",
    "        if query_title:\n",
    "            clinical_context += f\"{query_title}\\n\"\n",
    "        if query_content:\n",
    "            clinical_context += f\"{query_content}\\n\"\n",
    "    \n",
    "    # Get options text\n",
    "    options = row.get('options_en_cleaned', row.get('options_en', ['Yes', 'No', 'Not mentioned']))\n",
    "    if isinstance(options, list):\n",
    "        options_text = \", \".join(options)\n",
    "    else:\n",
    "        options_text = str(options)\n",
    "    \n",
    "    # Create the full query text with clinical context\n",
    "    query_text = (f\"MAIN QUESTION TO ANSWER: {question}\\n\"\n",
    "                 f\"Question Metadata: {metadata}\\n\"\n",
    "                 f\"{clinical_context}\"\n",
    "                 f\"Available Options (choose from these): {options_text}\")\n",
    "    \n",
    "    return query_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b122f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to provide an interface for retrieving combined data\n",
    "class AgenticRAGData:\n",
    "    def __init__(self, all_models_df, validation_df):\n",
    "        self.all_models_df = all_models_df\n",
    "        self.validation_df = validation_df\n",
    "        \n",
    "        # Create lookup dictionaries for faster access\n",
    "        self.model_predictions = {}\n",
    "        for (encounter_id, base_qid), group in all_models_df.groupby(['encounter_id', 'base_qid']):\n",
    "            self.model_predictions[(encounter_id, base_qid)] = group\n",
    "        \n",
    "        self.validation_data = {}\n",
    "        for _, row in validation_df.iterrows():\n",
    "            self.validation_data[(row['encounter_id'], row['base_qid'])] = row\n",
    "    \n",
    "    def get_combined_data(self, encounter_id, base_qid):\n",
    "        \"\"\"Retrieve combined data for a specific encounter and question.\"\"\"\n",
    "        # Get model predictions\n",
    "        model_preds = self.model_predictions.get((encounter_id, base_qid), None)\n",
    "        \n",
    "        # Get validation data\n",
    "        val_data = self.validation_data.get((encounter_id, base_qid), None)\n",
    "        \n",
    "        if model_preds is None:\n",
    "            print(f\"No model predictions found for encounter {encounter_id}, question {base_qid}\")\n",
    "            return None\n",
    "            \n",
    "        if val_data is None:\n",
    "            print(f\"No validation data found for encounter {encounter_id}, question {base_qid}\")\n",
    "            return None\n",
    "        \n",
    "        # Create query context if it doesn't exist\n",
    "        if 'query_context' not in val_data:\n",
    "            val_data['query_context'] = create_query_context(val_data)\n",
    "        \n",
    "        # Format model predictions as a dictionary\n",
    "        model_predictions_dict = {}\n",
    "        for _, row in model_preds.iterrows():\n",
    "            model_name = row['model_name']\n",
    "            \n",
    "            # Handle different data types for predictions\n",
    "            unique_preds = row.get('unique_predictions', [])\n",
    "            if isinstance(unique_preds, str):\n",
    "                try:\n",
    "                    unique_preds = ast.literal_eval(unique_preds)\n",
    "                except:\n",
    "                    unique_preds = [unique_preds]\n",
    "                    \n",
    "            raw_preds = row.get('all_raw_predictions', [])\n",
    "            if isinstance(raw_preds, str):\n",
    "                try:\n",
    "                    raw_preds = ast.literal_eval(raw_preds)\n",
    "                except:\n",
    "                    raw_preds = [raw_preds]\n",
    "                    \n",
    "            sorted_preds = row.get('all_sorted_predictions', [])\n",
    "            if isinstance(sorted_preds, str):\n",
    "                try:\n",
    "                    sorted_preds = ast.literal_eval(sorted_preds)\n",
    "                except:\n",
    "                    sorted_preds = [(str(raw_preds[0]), 1)] if raw_preds else []\n",
    "            \n",
    "            model_predictions_dict[model_name] = {\n",
    "                'combined_prediction': row.get('combined_prediction', ''),\n",
    "                'unique_predictions': unique_preds,\n",
    "                'all_raw_predictions': raw_preds,\n",
    "                'all_sorted_predictions': sorted_preds\n",
    "            }\n",
    "        \n",
    "        # Get ground truth data\n",
    "        ground_truth = val_data.get('ground_truth', {})\n",
    "        if not ground_truth:\n",
    "            # If ground_truth is not already processed, extract it from valid_answers\n",
    "            valid_answers = val_data.get('valid_answers', [])\n",
    "            if valid_answers:\n",
    "                # Process valid_answers similarly to how it's done in load_validation_dataset\n",
    "                if isinstance(valid_answers, str):\n",
    "                    try:\n",
    "                        valid_answers = ast.literal_eval(valid_answers)\n",
    "                    except:\n",
    "                        if ',' in valid_answers:\n",
    "                            valid_answers = [ans.strip() for ans in valid_answers.split(',')]\n",
    "                        else:\n",
    "                            valid_answers = [valid_answers.strip()]\n",
    "                \n",
    "                # Clean answers\n",
    "                cleaned_answers = []\n",
    "                for ans in valid_answers:\n",
    "                    if isinstance(ans, str):\n",
    "                        cleaned_ans = ans.strip(\"'\\\" \").replace(\" (please specify)\", \"\")\n",
    "                        cleaned_answers.append(cleaned_ans)\n",
    "                    else:\n",
    "                        cleaned_answers.append(str(ans).strip(\"'\\\" \"))\n",
    "                \n",
    "                ground_truth = {\n",
    "                    'raw_answers': valid_answers,\n",
    "                    'cleaned_answers': cleaned_answers,\n",
    "                    'combined_answer': \", \".join(cleaned_answers)\n",
    "                }\n",
    "        \n",
    "        # Return combined data with all images and ground truth\n",
    "        return {\n",
    "            'encounter_id': encounter_id,\n",
    "            'base_qid': base_qid,\n",
    "            'query_context': val_data['query_context'],\n",
    "            'images': val_data.get('all_images', []),  # Use all_images that contains multiple image paths\n",
    "            'options': val_data.get('options_en_cleaned', val_data.get('options_en', [])),\n",
    "            'question_type': val_data.get('question_type_en', ''),\n",
    "            'question_category': val_data.get('question_category_en', ''),\n",
    "            'ground_truth': ground_truth,  # Add ground truth to the result\n",
    "            'model_predictions': model_predictions_dict\n",
    "        }\n",
    "    \n",
    "    def get_all_encounter_question_pairs(self):\n",
    "        \"\"\"Return a list of all unique encounter_id, base_qid pairs.\"\"\"\n",
    "        return list(self.validation_data.keys())\n",
    "    \n",
    "    def get_sample_data(self, n=5):\n",
    "        \"\"\"Get a sample of combined data for n random encounter-question pairs.\"\"\"\n",
    "        import random\n",
    "        \n",
    "        all_pairs = self.get_all_encounter_question_pairs()\n",
    "        sample_pairs = random.sample(all_pairs, min(n, len(all_pairs)))\n",
    "        \n",
    "        return [self.get_combined_data(encounter_id, base_qid) for encounter_id, base_qid in sample_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34db9f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation dataset from /storage/scratch1/2/kthakrar3/mediqa-magic-v2/outputs/val_dataset.csv\n",
      "Loaded validation dataset with 1413 rows\n",
      "Created grouped validation dataset with 504 unique encounter-question pairs\n"
     ]
    }
   ],
   "source": [
    "val_data_dir = os.path.join(os.getcwd(), \"outputs\")\n",
    "val_dataset_path = os.path.join(val_data_dir, \"val_dataset.csv\")\n",
    "validation_df = load_validation_dataset(val_dataset_path)\n",
    "agentic_data = AgenticRAGData(all_models_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52f7bbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample combined data:\n",
      "Encounter: ENC00862, Question: CQID012\n",
      "Question type: Size\n",
      "Options: ['size of thumb nail', 'size of palm', 'larger area', 'Not mentioned']\n",
      "\n",
      "Query context:\n",
      "MAIN QUESTION TO ANSWER: How large are the affected areas?\n",
      "Question Metadata: Type: Size, Category: General\n",
      "Background Clinical Information (to help with your analysis):\n",
      "See picture.  Is this Mucoid cyst?\n",
      "It happens on the thumb, for 8 years already.  It is not itchy or painful.  It doesn't affect the sense there.  The size is 1 cm X 1 cm.  The nail has been deformed to a wavy shape becasue of the pressing.  Is this myxoid cyst?\n",
      "Available Options (choose from these): size of thumb nail, size of palm, larger area, Not mentioned\n",
      "\n",
      "Ground Truth:\n",
      "  Answer: size of thumb nail\n",
      "\n",
      "Model predictions:\n",
      "\n",
      "  Model: gemma-3-12b-it\n",
      "  Prediction: nan\n",
      "\n",
      "  Model: Qwen2-VL-7B-Instruct\n",
      "  Prediction: size of thumb nail, size of palm, 1 cm x 1 cm, larger area\n",
      "\n",
      "  Model: Qwen2-VL-2B-Instruct\n",
      "  Prediction: not mentioned(4, 287), (731, 996)\n",
      "\n",
      "  Model: gemma-3-4b-it\n",
      "  Prediction: size of thumb nail, size of palm, 1 cm x 1 cm\n",
      "\n",
      "  Model: Llama-3.2-11B-Vision-Instruct\n",
      "  Prediction: size of thumb nail, larger area\n",
      "\n",
      "  Model: Qwen2.5-VL-7B-Instruct\n",
      "  Prediction: size of thumb nail, larger area\n",
      "\n",
      "  Model: Qwen2.5-VL-3B-Instruct\n",
      "  Prediction: size of thumb nail, 1 cm x 1 cm\n",
      "\n",
      "Available images:\n",
      "  Image 1: IMG_ENC00862_00001.jpg\n",
      "  Image 2: IMG_ENC00862_00002.jpg\n",
      "  Image 3: IMG_ENC00862_00003.jpg\n",
      "  Image 4: IMG_ENC00862_00004.jpg\n",
      "  Image 5: IMG_ENC00862_00005.jpg\n",
      "  Image 6: IMG_ENC00862_00006.jpg\n"
     ]
    }
   ],
   "source": [
    "# To see the modified output with ground truth:\n",
    "def print_sample_with_ground_truth(sample_data):\n",
    "    \"\"\"Print sample data including ground truth for validation\"\"\"\n",
    "    print(f\"\\nSample combined data:\")\n",
    "    print(f\"Encounter: {sample_data['encounter_id']}, Question: {sample_data['base_qid']}\")\n",
    "    print(f\"Question type: {sample_data['question_type']}\")\n",
    "    print(f\"Options: {sample_data['options']}\")\n",
    "    \n",
    "    print(\"\\nQuery context:\")\n",
    "    print(sample_data['query_context'])\n",
    "    \n",
    "    # Print ground truth\n",
    "    if 'ground_truth' in sample_data and sample_data['ground_truth']:\n",
    "        print(\"\\nGround Truth:\")\n",
    "        print(f\"  Answer: {sample_data['ground_truth'].get('combined_answer', 'Not available')}\")\n",
    "    else:\n",
    "        print(\"\\nGround Truth: Not available\")\n",
    "    \n",
    "    print(\"\\nModel predictions:\")\n",
    "    for model_name, predictions in sample_data['model_predictions'].items():\n",
    "        print(f\"\\n  Model: {model_name}\")\n",
    "        print(f\"  Prediction: {predictions['combined_prediction']}\")\n",
    "        \n",
    "    # Print image paths\n",
    "    print(\"\\nAvailable images:\")\n",
    "    for i, img_path in enumerate(sample_data['images']):\n",
    "        print(f\"  Image {i+1}: {os.path.basename(img_path)}\")\n",
    "\n",
    "# Example usage:\n",
    "sample_data = agentic_data.get_sample_data(1)[0]\n",
    "print_sample_with_ground_truth(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdb874a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encounter_id': 'ENC00862',\n",
       " 'base_qid': 'CQID012',\n",
       " 'query_context': \"MAIN QUESTION TO ANSWER: How large are the affected areas?\\nQuestion Metadata: Type: Size, Category: General\\nBackground Clinical Information (to help with your analysis):\\nSee picture.  Is this Mucoid cyst?\\nIt happens on the thumb, for 8 years already.  It is not itchy or painful.  It doesn't affect the sense there.  The size is 1 cm X 1 cm.  The nail has been deformed to a wavy shape becasue of the pressing.  Is this myxoid cyst?\\nAvailable Options (choose from these): size of thumb nail, size of palm, larger area, Not mentioned\",\n",
       " 'images': ['/storage/scratch1/2/kthakrar3/mediqa-magic-v2/2025_dataset/valid/images_valid/IMG_ENC00862_00001.jpg',\n",
       "  '/storage/scratch1/2/kthakrar3/mediqa-magic-v2/2025_dataset/valid/images_valid/IMG_ENC00862_00002.jpg',\n",
       "  '/storage/scratch1/2/kthakrar3/mediqa-magic-v2/2025_dataset/valid/images_valid/IMG_ENC00862_00003.jpg',\n",
       "  '/storage/scratch1/2/kthakrar3/mediqa-magic-v2/2025_dataset/valid/images_valid/IMG_ENC00862_00004.jpg',\n",
       "  '/storage/scratch1/2/kthakrar3/mediqa-magic-v2/2025_dataset/valid/images_valid/IMG_ENC00862_00005.jpg',\n",
       "  '/storage/scratch1/2/kthakrar3/mediqa-magic-v2/2025_dataset/valid/images_valid/IMG_ENC00862_00006.jpg'],\n",
       " 'options': ['size of thumb nail',\n",
       "  'size of palm',\n",
       "  'larger area',\n",
       "  'Not mentioned'],\n",
       " 'question_type': 'Size',\n",
       " 'question_category': 'General',\n",
       " 'ground_truth': {'raw_answers': ['size of thumb nail'],\n",
       "  'cleaned_answers': ['size of thumb nail'],\n",
       "  'combined_answer': 'size of thumb nail'},\n",
       " 'model_predictions': {'gemma-3-12b-it': {'combined_prediction': nan,\n",
       "   'unique_predictions': [''],\n",
       "   'all_raw_predictions': ['', '', '', '', '', ''],\n",
       "   'all_sorted_predictions': [('', 6)]},\n",
       "  'Qwen2-VL-7B-Instruct': {'combined_prediction': 'size of thumb nail, size of palm, 1 cm x 1 cm, larger area',\n",
       "   'unique_predictions': ['size of thumb nail',\n",
       "    'size of palm',\n",
       "    '1 cm x 1 cm',\n",
       "    'larger area'],\n",
       "   'all_raw_predictions': ['Not mentioned',\n",
       "    '1 cm X 1 cm',\n",
       "    'size of thumb nail',\n",
       "    'size of palm',\n",
       "    'size of thumb nail',\n",
       "    'size of palm',\n",
       "    'larger area',\n",
       "    'size of thumb nail',\n",
       "    'size of palm',\n",
       "    'size of thumb nail',\n",
       "    'Not mentioned'],\n",
       "   'all_sorted_predictions': [('size of thumb nail', 4),\n",
       "    ('size of palm', 3),\n",
       "    ('not mentioned', 2),\n",
       "    ('1 cm x 1 cm', 1),\n",
       "    ('larger area', 1)]},\n",
       "  'Qwen2-VL-2B-Instruct': {'combined_prediction': 'not mentioned(4, 287), (731, 996)',\n",
       "   'unique_predictions': ['not mentioned(4', '287)', '(731', '996)'],\n",
       "   'all_raw_predictions': ['Not mentioned',\n",
       "    'Not mentioned',\n",
       "    'Not mentioned(4',\n",
       "    '287)',\n",
       "    '(731',\n",
       "    '996)',\n",
       "    'Not mentioned',\n",
       "    'Not mentioned',\n",
       "    'Not mentioned'],\n",
       "   'all_sorted_predictions': [('not mentioned', 5),\n",
       "    ('not mentioned(4', 1),\n",
       "    ('287)', 1),\n",
       "    ('(731', 1),\n",
       "    ('996)', 1)]},\n",
       "  'gemma-3-4b-it': {'combined_prediction': 'size of thumb nail, size of palm, 1 cm x 1 cm',\n",
       "   'unique_predictions': ['size of thumb nail', 'size of palm', '1 cm x 1 cm'],\n",
       "   'all_raw_predictions': ['size of thumb nail',\n",
       "    'size of palm',\n",
       "    'size of thumb nail',\n",
       "    'size of palm',\n",
       "    'Not mentioned',\n",
       "    'size of thumb nail',\n",
       "    '1 cm X 1 cm',\n",
       "    '1 cm X 1 cm',\n",
       "    'size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    'size of palm',\n",
       "    '1 cm x 1 cm',\n",
       "    'size of thumb nail'],\n",
       "   'all_sorted_predictions': [('size of thumb nail', 6),\n",
       "    ('size of palm', 3),\n",
       "    ('1 cm x 1 cm', 3),\n",
       "    ('not mentioned', 1)]},\n",
       "  'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'size of thumb nail, larger area',\n",
       "   'unique_predictions': ['size of thumb nail', 'larger area'],\n",
       "   'all_raw_predictions': ['Not mentioned',\n",
       "    'Not mentioned',\n",
       "    'size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    'larger area',\n",
       "    'Not mentioned',\n",
       "    'size of thumb nail',\n",
       "    'Not mentioned'],\n",
       "   'all_sorted_predictions': [('not mentioned', 4),\n",
       "    ('size of thumb nail', 3),\n",
       "    ('larger area', 1)]},\n",
       "  'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'size of thumb nail, larger area',\n",
       "   'unique_predictions': ['size of thumb nail', 'larger area'],\n",
       "   'all_raw_predictions': ['size of thumb nail',\n",
       "    'larger area',\n",
       "    'size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    'larger area',\n",
       "    'size of thumb nail',\n",
       "    'larger area'],\n",
       "   'all_sorted_predictions': [('size of thumb nail', 6), ('larger area', 3)]},\n",
       "  'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'size of thumb nail, 1 cm x 1 cm',\n",
       "   'unique_predictions': ['size of thumb nail', '1 cm x 1 cm'],\n",
       "   'all_raw_predictions': ['size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    'size of thumb nail',\n",
       "    '1 cm X 1 cm',\n",
       "    'not mentioned'],\n",
       "   'all_sorted_predictions': [('size of thumb nail', 5),\n",
       "    ('1 cm x 1 cm', 1),\n",
       "    ('not mentioned', 1)]}}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f141fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "# Initialize the Gemini client\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "819e4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structured_dermatological_analysis(sample_data):\n",
    "    \"\"\"\n",
    "    Extract structured analysis of all images for an encounter, covering all question types.\n",
    "    \n",
    "    Args:\n",
    "        sample_data: Dictionary containing encounter data with images\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with structured dermatological analysis\n",
    "    \"\"\"\n",
    "    encounter_id = sample_data['encounter_id']\n",
    "    image_paths = sample_data['images']\n",
    "    \n",
    "    # Create a list to store analysis of each image\n",
    "    image_analyses = []\n",
    "    \n",
    "    # Modified prompt for structured dermatological analysis\n",
    "        \n",
    "    structured_prompt = f\"\"\"As dermatology specialist analyzing skin images, extract and structure all clinically relevant information from this dermatological image.\n",
    "\n",
    "    Organize your response in a JSON dictionary:\n",
    "\n",
    "    1. SIZE: Approximate dimensions of lesions/affected areas, size comparison (thumbnail, palm, larger), Relative size comparisons for multiple lesions\n",
    "    2. SITE_LOCATION: Visible body parts in the image, body areas showing lesions/abnormalities, Specific anatomical locations affected\n",
    "    3. SKIN_DESCRIPTION: Lesion morphology (flat, raised, depressed), Texture of affected areas, Surface characteristics (scales, crust, fluid), Appearance of lesion boundaries\n",
    "    4. LESION_COLOR: Predominant color(s) of affected areas, Color variations within lesions, Color comparison to normal skin, Color distribution patterns\n",
    "    5. LESION_COUNT: Number of distinct lesions/affected areas, Single vs multiple presentation, Distribution pattern if multiple, Any counting limitations\n",
    "    6. EXTENT: How widespread the condition appears, Localized vs widespread assessment, Approximate percentage of visible skin affected, Limitations in determining full extent\n",
    "    7. TEXTURE: Expected tactile qualities, Smooth vs rough assessment, Notable textural features, Texture consistency across affected areas\n",
    "    8. ONSET_INDICATORS: Visual clues about condition duration, Acute vs chronic presentation features, Healing/progression/chronicity signs, Note: precise timing cannot be determined from images\n",
    "    9. ITCH_INDICATORS: Scratch marks/excoriations/trauma signs, Features associated with itchy conditions, Pruritic vs non-pruritic visual indicators, Note: sensation cannot be directly observed\n",
    "    10. OVERALL_IMPRESSION: Brief description (1-2 sentences), Key diagnostic features, Potential diagnoses (2-3)\n",
    "    \n",
    "    Be concise and use medical terminology where appropriate. If information for a section is \n",
    "    cannot be determined, state \"Cannot determine from image\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process each image\n",
    "    for idx, img_path in enumerate(image_paths):\n",
    "        try:\n",
    "            # Load image\n",
    "            image = Image.open(img_path)\n",
    "            \n",
    "            # Analyze image with structured prompt\n",
    "            print(f\"Analyzing image {idx+1}/{len(image_paths)} for encounter {encounter_id}\")\n",
    "            \n",
    "            # Create a request for Gemini\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash-preview-04-17\",\n",
    "                contents=[structured_prompt, image]\n",
    "            )\n",
    "            \n",
    "            # Extract the analysis text and parse as JSON\n",
    "            analysis_text = response.text\n",
    "            print(f\"Analysis text received (length: {len(analysis_text)})\")\n",
    "            \n",
    "            # Clean up the response to ensure it's valid JSON\n",
    "            # Remove markdown code block indicators and any non-JSON text\n",
    "            cleaned_text = analysis_text\n",
    "            if \"```json\" in cleaned_text:\n",
    "                cleaned_text = cleaned_text.split(\"```json\")[1]\n",
    "            if \"```\" in cleaned_text:\n",
    "                cleaned_text = cleaned_text.split(\"```\")[0]\n",
    "            \n",
    "            # Try to parse as JSON\n",
    "            try:\n",
    "                import json\n",
    "                structured_analysis = json.loads(cleaned_text)\n",
    "                print(f\"Successfully parsed structured analysis for image {idx+1}\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Could not parse analysis as JSON for image {idx+1}\")\n",
    "                structured_analysis = {\"parse_error\": \"Could not parse as JSON\", \"raw_text\": analysis_text}\n",
    "            \n",
    "            # Store result\n",
    "            image_analyses.append({\n",
    "                \"image_index\": idx + 1,\n",
    "                \"image_path\": os.path.basename(img_path),\n",
    "                \"structured_analysis\": structured_analysis\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing image {img_path}: {str(e)}\")\n",
    "            image_analyses.append({\n",
    "                \"image_index\": idx + 1,\n",
    "                \"image_path\": os.path.basename(img_path),\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    # Generate aggregated analysis across all images\n",
    "    aggregated_analysis = aggregate_structured_analyses(image_analyses, encounter_id)\n",
    "    \n",
    "    # Return combined results\n",
    "    return {\n",
    "        \"encounter_id\": encounter_id,\n",
    "        \"image_count\": len(image_paths),\n",
    "        \"individual_analyses\": image_analyses,\n",
    "        \"aggregated_analysis\": aggregated_analysis\n",
    "    }\n",
    "\n",
    "def aggregate_structured_analyses(image_analyses, encounter_id):\n",
    "    \"\"\"Aggregate structured analyses from multiple images into a single structured analysis\"\"\"\n",
    "    \n",
    "    # Skip if there are no valid analyses\n",
    "    valid_analyses = [a for a in image_analyses if \"error\" not in a and \"structured_analysis\" in a]\n",
    "    print(f\"Aggregating {len(valid_analyses)} valid structured analyses for encounter {encounter_id}\")\n",
    "    \n",
    "    if not valid_analyses:\n",
    "        return {\n",
    "            \"error\": \"No valid analyses to aggregate\",\n",
    "            \"message\": \"Unable to generate aggregated analysis due to errors in individual analyses.\"\n",
    "        }\n",
    "    \n",
    "    # If there's only one image, return its analysis as the aggregated result\n",
    "    if len(valid_analyses) == 1:\n",
    "        return valid_analyses[0][\"structured_analysis\"]\n",
    "    \n",
    "    # For multiple images, create a prompt for aggregation\n",
    "    # Extract analysis JSONs to include in the prompt\n",
    "    analysis_jsons = []\n",
    "    for analysis in valid_analyses:\n",
    "        import json\n",
    "        analysis_json = json.dumps(analysis[\"structured_analysis\"])\n",
    "        analysis_jsons.append(f\"Image {analysis['image_index']} ({analysis['image_path']}): {analysis_json}\")\n",
    "    \n",
    "    # Create an aggregation prompt\n",
    "    aggregation_prompt = f\"\"\"As dermatology specialist reviewing multiple skin image analyses for the same patient, combine these analyses and organize your response in a JSON dictionary:\n",
    "\n",
    "    1. SIZE: Approximate dimensions of lesions/affected areas, size comparison (thumbnail, palm, larger), Relative size comparisons for multiple lesions\n",
    "    2. SITE_LOCATION: Visible body parts in the image, body areas showing lesions/abnormalities, Specific anatomical locations affected\n",
    "    3. SKIN_DESCRIPTION: Lesion morphology (flat, raised, depressed), Texture of affected areas, Surface characteristics (scales, crust, fluid), Appearance of lesion boundaries\n",
    "    4. LESION_COLOR: Predominant color(s) of affected areas, Color variations within lesions, Color comparison to normal skin, Color distribution patterns\n",
    "    5. LESION_COUNT: Number of distinct lesions/affected areas, Single vs multiple presentation, Distribution pattern if multiple, Any counting limitations\n",
    "    6. EXTENT: How widespread the condition appears, Localized vs widespread assessment, Approximate percentage of visible skin affected, Limitations in determining full extent\n",
    "    7. TEXTURE: Expected tactile qualities, Smooth vs rough assessment, Notable textural features, Texture consistency across affected areas\n",
    "    8. ONSET_INDICATORS: Visual clues about condition duration, Acute vs chronic presentation features, Healing/progression/chronicity signs, Note: precise timing cannot be determined from images\n",
    "    9. ITCH_INDICATORS: Scratch marks/excoriations/trauma signs, Features associated with itchy conditions, Pruritic vs non-pruritic visual indicators, Note: sensation cannot be directly observed\n",
    "    10. OVERALL_IMPRESSION: Brief description (1-2 sentences), Key diagnostic features, Potential diagnoses (2-3)\n",
    "        \n",
    "    {' '.join(analysis_jsons)}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call Gemini for the aggregated analysis\n",
    "        import json\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-04-17\",\n",
    "            contents=[aggregation_prompt]\n",
    "        )\n",
    "        \n",
    "        aggregation_text = response.text\n",
    "        print(f\"Aggregated analysis received (length: {len(aggregation_text)})\")\n",
    "        \n",
    "        # Clean up the response to ensure it's valid JSON\n",
    "        cleaned_text = aggregation_text\n",
    "        if \"```json\" in cleaned_text:\n",
    "            cleaned_text = cleaned_text.split(\"```json\")[1]\n",
    "        if \"```\" in cleaned_text:\n",
    "            cleaned_text = cleaned_text.split(\"```\")[0]\n",
    "        \n",
    "        # Try to parse as JSON\n",
    "        try:\n",
    "            aggregated_analysis = json.loads(cleaned_text)\n",
    "            print(f\"Successfully parsed aggregated analysis\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Could not parse aggregated analysis as JSON\")\n",
    "            aggregated_analysis = {\"parse_error\": \"Could not parse as JSON\", \"raw_text\": aggregation_text}\n",
    "        \n",
    "        return aggregated_analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating aggregated analysis for encounter {encounter_id}: {str(e)}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"aggregation_error\": \"Failed to generate aggregated analysis\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2196fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_encounter_image_analyses(agentic_data):\n",
    "    \"\"\"\n",
    "    Process comprehensive image analyses for all unique encounters.\n",
    "    \n",
    "    Args:\n",
    "        agentic_data: AgenticRAGData instance containing all encounter data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping encounter_ids to comprehensive image analyses\n",
    "    \"\"\"\n",
    "    # Get all unique encounter IDs\n",
    "    all_pairs = agentic_data.get_all_encounter_question_pairs()\n",
    "    unique_encounters = set(pair[0] for pair in all_pairs)\n",
    "    \n",
    "    print(f\"Processing image analyses for {len(unique_encounters)} unique encounters\")\n",
    "    \n",
    "    # Process each encounter (using the first question for that encounter)\n",
    "    encounter_image_analyses = {}\n",
    "    for encounter_id in unique_encounters:\n",
    "        # Find the first question for this encounter\n",
    "        for pair in all_pairs:\n",
    "            if pair[0] == encounter_id:\n",
    "                # Get the full data for this encounter-question pair\n",
    "                sample_data = agentic_data.get_combined_data(pair[0], pair[1])\n",
    "                \n",
    "                # Extract and store comprehensive image analysis\n",
    "                image_analysis = extract_comprehensive_image_analysis(sample_data)\n",
    "                encounter_image_analyses[encounter_id] = image_analysis\n",
    "                \n",
    "                # Print progress\n",
    "                print(f\"Processed comprehensive image analysis for encounter {encounter_id}\")\n",
    "                \n",
    "                # Since we only need one question per encounter, break after finding the first\n",
    "                break\n",
    "    \n",
    "    return encounter_image_analyses\n",
    "\n",
    "# Usage example for a single encounter\n",
    "def extract_single_encounter_image_analysis(sample_data):\n",
    "    \"\"\"Extract comprehensive image analysis for a single encounter\"\"\"\n",
    "    encounter_id = sample_data['encounter_id']\n",
    "    print(f\"Extracting comprehensive image analysis for encounter {encounter_id}\")\n",
    "    \n",
    "    image_analysis = extract_comprehensive_image_analysis(sample_data)\n",
    "    \n",
    "    # Save to a file for future reference\n",
    "    import json\n",
    "    with open(f\"image_analysis_{encounter_id}.json\", \"w\") as f:\n",
    "        json.dump(image_analysis, f, indent=2)\n",
    "    \n",
    "    print(f\"Extracted and saved comprehensive image analysis for encounter {encounter_id}\")\n",
    "    return image_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47fecd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_specific_encounter(agentic_data, target_encounter_id):\n",
    "#     \"\"\"\n",
    "#     Process comprehensive image analysis for a specific encounter ID.\n",
    "    \n",
    "#     Args:\n",
    "#         agentic_data: AgenticRAGData instance containing all encounter data\n",
    "#         target_encounter_id: The specific encounter ID to process\n",
    "        \n",
    "#     Returns:\n",
    "#         Dictionary with comprehensive image analysis for the specified encounter\n",
    "#     \"\"\"\n",
    "#     # Get all pairs for this encounter\n",
    "#     all_pairs = agentic_data.get_all_encounter_question_pairs()\n",
    "#     encounter_pairs = [pair for pair in all_pairs if pair[0] == target_encounter_id]\n",
    "    \n",
    "#     if not encounter_pairs:\n",
    "#         print(f\"No data found for encounter {target_encounter_id}\")\n",
    "#         return None\n",
    "    \n",
    "#     # Get the full data for the first question of this encounter\n",
    "#     first_pair = encounter_pairs[0]\n",
    "#     sample_data = agentic_data.get_combined_data(first_pair[0], first_pair[1])\n",
    "    \n",
    "#     # Extract comprehensive image analysis\n",
    "#     image_analysis = extract_comprehensive_image_analysis(sample_data)\n",
    "    \n",
    "#     # Save to a file for future reference\n",
    "#     import json\n",
    "#     with open(f\"image_analysis_{target_encounter_id}.json\", \"w\") as f:\n",
    "#         json.dump(image_analysis, f, indent=2)\n",
    "    \n",
    "#     print(f\"Processed comprehensive image analysis for encounter {target_encounter_id}\")\n",
    "#     return {target_encounter_id: image_analysis}\n",
    "\n",
    "# # Usage\n",
    "# specific_analysis = process_specific_encounter(agentic_data, \"ENC00902\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57b47f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a single sample\n",
    "sample_data = agentic_data.get_sample_data(1)[0]\n",
    "comprehensive_image_analysis = extract_single_encounter_image_analysis(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive_image_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4686ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clinical_context(sample_data):\n",
    "    \"\"\"\n",
    "    Extract structured clinical information from an encounter's query title and content.\n",
    "    \n",
    "    Args:\n",
    "        sample_data: Dictionary containing encounter data with query_context\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with structured clinical information\n",
    "    \"\"\"\n",
    "    # Extract encounter details\n",
    "    encounter_id = sample_data['encounter_id']\n",
    "    \n",
    "    # Get the clinical context from query_context\n",
    "    query_context = sample_data['query_context']\n",
    "    \n",
    "    # Extract just the clinical part\n",
    "    clinical_lines = []\n",
    "    capturing = False\n",
    "    for line in query_context.split('\\n'):\n",
    "        if \"Background Clinical Information\" in line:\n",
    "            capturing = True\n",
    "            continue\n",
    "        elif \"Available Options\" in line:\n",
    "            capturing = False\n",
    "        elif capturing:\n",
    "            clinical_lines.append(line)\n",
    "    \n",
    "    clinical_text = \"\\n\".join(clinical_lines).strip()\n",
    "    \n",
    "    # If there's no clinical information, return empty structure\n",
    "    if not clinical_text:\n",
    "        return {\n",
    "            \"encounter_id\": encounter_id,\n",
    "            \"clinical_summary\": \"No clinical information available\"\n",
    "        }\n",
    "    \n",
    "    # Create prompt for Gemini to extract structured information\n",
    "    prompt = f\"\"\"You are a dermatology specialist analyzing patient information. \n",
    "    Extract and structure all clinically relevant information from this patient description:\n",
    "\n",
    "    {clinical_text}\n",
    "\n",
    "    Organize your response in the following JSON structure:\n",
    "\n",
    "    1. DEMOGRAPHICS: Age, sex, and any other demographic data\n",
    "    2. SITE_LOCATION: Body parts affected by the condition as described in the text\n",
    "    3. SKIN_DESCRIPTION: Any mention of lesion morphology (flat, raised, depressed), texture, surface characteristics (scales, crust, fluid), appearance of lesion boundaries\n",
    "    4. LESION_COLOR: Any description of color(s) of affected areas, color variations, comparison to normal skin\n",
    "    5. LESION_COUNT: Any information about number of lesions, single vs multiple presentation, distribution pattern\n",
    "    6. EXTENT: How widespread the condition appears based on the description, localized vs widespread\n",
    "    7. TEXTURE: Any description of tactile qualities, smooth vs rough, notable textural features\n",
    "    8. ONSET_INDICATORS: Information about onset, duration, progression, or evolution of symptoms\n",
    "    9. ITCH_INDICATORS: Mentions of scratching, itchiness, or other sensory symptoms\n",
    "    10. OTHER_SYMPTOMS: Any additional symptoms mentioned (pain, burning, etc.)\n",
    "    11. TRIGGERS: Identified factors that worsen/improve the condition\n",
    "    12. HISTORY: Relevant past medical history or previous treatments\n",
    "    13. DIAGNOSTIC_CONSIDERATIONS: Any mentioned or suggested diagnoses in the text\n",
    "\n",
    "    Be concise and use medical terminology where appropriate. If information for a section is \n",
    "    not available, indicate \"Not mentioned\".\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call Gemini\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-04-17\",\n",
    "            contents=[prompt]\n",
    "        )\n",
    "        \n",
    "        # Return structured result\n",
    "        return {\n",
    "            \"encounter_id\": encounter_id,\n",
    "            \"raw_clinical_text\": clinical_text,\n",
    "            \"structured_clinical_context\": response.text\n",
    "        }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting clinical context for encounter {encounter_id}: {str(e)}\")\n",
    "        return {\n",
    "            \"encounter_id\": encounter_id,\n",
    "            \"raw_clinical_text\": clinical_text,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "def process_encounter_clinical_contexts(agentic_data):\n",
    "    \"\"\"\n",
    "    Process clinical contexts for all unique encounters.\n",
    "    \n",
    "    Args:\n",
    "        agentic_data: AgenticRAGData instance containing all encounter data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping encounter_ids to structured clinical contexts\n",
    "    \"\"\"\n",
    "    # Get all unique encounter IDs\n",
    "    all_pairs = agentic_data.get_all_encounter_question_pairs()\n",
    "    unique_encounters = set(pair[0] for pair in all_pairs)\n",
    "    \n",
    "    print(f\"Processing clinical contexts for {len(unique_encounters)} unique encounters\")\n",
    "    \n",
    "    # Process each encounter (using the first question for that encounter)\n",
    "    encounter_contexts = {}\n",
    "    for encounter_id in unique_encounters:\n",
    "        # Find the first question for this encounter\n",
    "        for pair in all_pairs:\n",
    "            if pair[0] == encounter_id:\n",
    "                # Get the full data for this encounter-question pair\n",
    "                sample_data = agentic_data.get_combined_data(pair[0], pair[1])\n",
    "                \n",
    "                # Extract and store clinical context\n",
    "                clinical_context = extract_clinical_context(sample_data)\n",
    "                encounter_contexts[encounter_id] = clinical_context\n",
    "                \n",
    "                # Print progress\n",
    "                print(f\"Processed clinical context for encounter {encounter_id}\")\n",
    "                \n",
    "                # Since we only need one question per encounter, break after finding the first\n",
    "                break\n",
    "    \n",
    "    return encounter_contexts\n",
    "\n",
    "# Usage example\n",
    "def extract_all_clinical_contexts(agentic_data):\n",
    "    \"\"\"Extract clinical contexts for all encounters\"\"\"\n",
    "    clinical_contexts = process_encounter_clinical_contexts(agentic_data)\n",
    "    \n",
    "    # Save to a file for future use\n",
    "    import json\n",
    "    with open(\"clinical_contexts.json\", \"w\") as f:\n",
    "        json.dump(clinical_contexts, f, indent=2)\n",
    "    \n",
    "    print(f\"Extracted and saved clinical contexts for {len(clinical_contexts)} encounters\")\n",
    "    return clinical_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "105ac339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encounter ID: ENC00857\n",
      "Raw clinical text:\n",
      "Would experts here please help take a look.\n",
      "Would experts here take a look.\n",
      "Patient is 34 years old, female.  There grows figure like pattern all over the body, with the exception of palms and soles.  Has been like that for 20 years, and growing more.  Would experts here take a look and advise what disease it is, and the treatment.  Thanks.\n",
      "Structured clinical context:\n",
      "```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"34 years\",\n",
      "    \"Sex\": \"Female\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": \"Widespread distribution, excluding palms and soles.\",\n",
      "  \"SKIN_DESCRIPTION\": \"Lesions described as forming a \\\"figure like pattern\\\". Morphology (e.g., papular, plaque), surface characteristics (e.g., scaling), and boundaries are not described.\",\n",
      "  \"LESION_COLOR\": \"Not mentioned\",\n",
      "  \"LESION_COUNT\": \"Multiple lesions, distributed in a pattern.\",\n",
      "  \"EXTENT\": \"Diffuse distribution over the body surface area, sparing acral sites (palms and soles).\",\n",
      "  \"TEXTURE\": \"Not mentioned\",\n",
      "  \"ONSET_INDICATORS\": {\n",
      "    \"Duration\": \"20 years\",\n",
      "    \"Progression\": \"Reported as \\\"growing more\\\".\"\n",
      "  },\n",
      "  \"ITCH_INDICATORS\": \"Not mentioned\",\n",
      "  \"OTHER_SYMPTOMS\": \"Not mentioned\",\n",
      "  \"TRIGGERS\": \"Not mentioned\",\n",
      "  \"HISTORY\": \"Not mentioned\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": \"Not mentioned\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Get a sample data point (one encounter-question pair)\n",
    "sample_data = agentic_data.get_sample_data(1)[0]\n",
    "\n",
    "# Extract clinical context for just this one encounter\n",
    "clinical_context = extract_clinical_context(sample_data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Encounter ID: {clinical_context['encounter_id']}\")\n",
    "print(f\"Raw clinical text:\\n{clinical_context['raw_clinical_text']}\")\n",
    "print(f\"Structured clinical context:\\n{clinical_context['structured_clinical_context']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb4145f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_reasoning_layer(encounter_id, base_qid, image_analysis, clinical_context, sample_data):\n",
    "    \"\"\"\n",
    "    Apply a reasoning layer to determine the best answer(s) for a specific encounter-question pair.\n",
    "    \n",
    "    Args:\n",
    "        encounter_id: The encounter ID\n",
    "        base_qid: The question ID\n",
    "        image_analysis: Structured image analysis for this encounter\n",
    "        clinical_context: Structured clinical context for this encounter\n",
    "        sample_data: Combined data for this encounter-question pair\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with reasoning and final answer(s)\n",
    "    \"\"\"\n",
    "    # Extract relevant data\n",
    "    question_text = sample_data['query_context'].split(\"MAIN QUESTION TO ANSWER:\")[1].split(\"\\n\")[0].strip()\n",
    "    print(\"question_text: \", question_text)\n",
    "    options = sample_data['options']\n",
    "    print(\"options: \", options)\n",
    "    question_type = sample_data['question_type']\n",
    "    print(\"question_type: \", question_type)\n",
    "    model_predictions = sample_data['model_predictions']\n",
    "    print(\"model_predictions: \", model_predictions)\n",
    "    \n",
    "    # Format model predictions for the prompt\n",
    "    model_prediction_text = \"\"\n",
    "    for model_name, predictions in model_predictions.items():\n",
    "        combined_pred = predictions.get('combined_prediction', '')\n",
    "        if isinstance(combined_pred, float) and pd.isna(combined_pred):\n",
    "            combined_pred = \"No prediction\"\n",
    "        model_prediction_text += f\"- {model_name}: {combined_pred}\\n\"\n",
    "    print(model_prediction_text)\n",
    "    \n",
    "    # Create a prompt for the reasoning layer\n",
    "    prompt = f\"\"\"You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
    "\n",
    "    QUESTION: {question_text}\n",
    "    QUESTION TYPE: {question_type}\n",
    "    OPTIONS: {\", \".join(options)}\n",
    "\n",
    "    IMAGE ANALYSIS:\n",
    "    {json.dumps(image_analysis['aggregated_analysis'], indent=2)}\n",
    "\n",
    "    CLINICAL CONTEXT:\n",
    "    {clinical_context['structured_clinical_context']}\n",
    "\n",
    "    MODEL PREDICTIONS:\n",
    "    {model_prediction_text}\n",
    "\n",
    "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
    "    1. Analyze the evidence from the image analysis and clinical context\n",
    "    2. Consider the model predictions, noting any consensus or disagreement\n",
    "    3. Provide a brief reasoning for your conclusion\n",
    "    4. Select the final answer(s) from the available options\n",
    "\n",
    "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
    "\n",
    "    Format your response as a JSON object with these fields:\n",
    "    1. \"reasoning\": Your step-by-step reasoning process\n",
    "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
    "\n",
    "    When providing your answer, strictly adhere to the available options and only select from them.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"prompt: {prompt}\")\n",
    "    try:\n",
    "        # Call Gemini for reasoning\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-04-17\",\n",
    "            contents=[prompt]\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        reasoning_text = response.text\n",
    "        print(\"reasoning_text: \", reasoning_text)\n",
    "        \n",
    "        # Clean up the response to ensure it's valid JSON\n",
    "        cleaned_text = reasoning_text\n",
    "        if \"```json\" in cleaned_text:\n",
    "            cleaned_text = cleaned_text.split(\"```json\")[1]\n",
    "        if \"```\" in cleaned_text:\n",
    "            cleaned_text = cleaned_text.split(\"```\")[0]\n",
    "            \n",
    "        print(\"cleaned_text: \", cleaned_text)\n",
    "        \n",
    "        # Parse JSON\n",
    "        try:\n",
    "            reasoning_result = json.loads(cleaned_text)\n",
    "            print(f\"Successfully parsed reasoning for {encounter_id}, {base_qid}\")\n",
    "            print(\"reasoning_result: \", reasoning_result)\n",
    "            \n",
    "            # Validate the answer against options\n",
    "            answer = reasoning_result.get('answer', '').lower()\n",
    "            print(\"answer: \", answer)\n",
    "            valid_answers = []\n",
    "            \n",
    "            # Handle comma-separated answers\n",
    "            if ',' in answer:\n",
    "                answer_parts = [part.strip() for part in answer.split(',')]\n",
    "                for part in answer_parts:\n",
    "                    for option in options:\n",
    "                        if part == option.lower():\n",
    "                            valid_answers.append(option)\n",
    "            else:\n",
    "                for option in options:\n",
    "                    if answer == option.lower():\n",
    "                        valid_answers.append(option)\n",
    "            \n",
    "            # Use \"Not mentioned\" if no valid answers found\n",
    "            if not valid_answers:\n",
    "                if \"not mentioned\" in answer:\n",
    "                    valid_answers = [\"Not mentioned\"]\n",
    "                else:\n",
    "                    print(f\"Warning: No valid answers found for {encounter_id}, {base_qid}\")\n",
    "                    valid_answers = [\"Not mentioned\"]\n",
    "            \n",
    "            # Update the result with validated answers\n",
    "            reasoning_result['validated_answer'] = \", \".join(valid_answers)\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Could not parse reasoning as JSON for {encounter_id}, {base_qid}\")\n",
    "            reasoning_result = {\n",
    "                \"reasoning\": \"Error parsing response.\",\n",
    "                \"answer\": \"Not mentioned\",\n",
    "                \"validated_answer\": \"Not mentioned\",\n",
    "                \"raw_text\": reasoning_text\n",
    "            }\n",
    "        \n",
    "        print(\"reasoning_result: \", reasoning_result)\n",
    "        \n",
    "        return reasoning_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error applying reasoning layer for {encounter_id}, {base_qid}: {str(e)}\")\n",
    "        return {\n",
    "            \"reasoning\": f\"Error: {str(e)}\",\n",
    "            \"answer\": \"Not mentioned\",\n",
    "            \"validated_answer\": \"Not mentioned\",\n",
    "            \"error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0282cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_encounters_with_reasoning(agentic_data):\n",
    "    \"\"\"\n",
    "    Process all encounters and questions with reasoning layer.\n",
    "    \n",
    "    Args:\n",
    "        agentic_data: AgenticRAGData instance containing all encounter data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with all encountered processed with reasoning\n",
    "    \"\"\"\n",
    "    # Get all encounter-question pairs\n",
    "    all_pairs = agentic_data.get_all_encounter_question_pairs()\n",
    "    print(f\"Processing {len(all_pairs)} encounter-question pairs with reasoning layer\")\n",
    "    \n",
    "    # Dictionary to store all results\n",
    "    all_results = {}\n",
    "    \n",
    "    # Dictionary to store image analyses and clinical contexts (to avoid recomputing)\n",
    "    image_analyses = {}\n",
    "    clinical_contexts = {}\n",
    "    \n",
    "    # Process each encounter-question pair\n",
    "    for i, (encounter_id, base_qid) in enumerate(all_pairs):\n",
    "        print(f\"Processing pair {i+1}/{len(all_pairs)}: {encounter_id}, {base_qid}\")\n",
    "        \n",
    "        # Get the combined data for this pair\n",
    "        sample_data = agentic_data.get_combined_data(encounter_id, base_qid)\n",
    "        if not sample_data:\n",
    "            print(f\"Warning: No data found for {encounter_id}, {base_qid}\")\n",
    "            continue\n",
    "        \n",
    "        # Get or compute image analysis for this encounter\n",
    "        if encounter_id not in image_analyses:\n",
    "            print(f\"  Computing image analysis for {encounter_id}\")\n",
    "            image_analyses[encounter_id] = extract_structured_dermatological_analysis(sample_data)\n",
    "        \n",
    "        # Get or compute clinical context for this encounter\n",
    "        if encounter_id not in clinical_contexts:\n",
    "            print(f\"  Computing clinical context for {encounter_id}\")\n",
    "            clinical_contexts[encounter_id] = extract_clinical_context(sample_data)\n",
    "        \n",
    "        # Apply reasoning layer\n",
    "        print(f\"  Applying reasoning layer for {encounter_id}, {base_qid}\")\n",
    "        reasoning_result = apply_reasoning_layer(\n",
    "            encounter_id,\n",
    "            base_qid,\n",
    "            image_analyses[encounter_id],\n",
    "            clinical_contexts[encounter_id],\n",
    "            sample_data\n",
    "        )\n",
    "        \n",
    "        # Store the result\n",
    "        if encounter_id not in all_results:\n",
    "            all_results[encounter_id] = {}\n",
    "        \n",
    "        all_results[encounter_id][base_qid] = {\n",
    "            \"query_context\": sample_data['query_context'],\n",
    "            \"options\": sample_data['options'],\n",
    "            \"model_predictions\": sample_data['model_predictions'],\n",
    "            \"reasoning_result\": reasoning_result,\n",
    "            \"final_answer\": reasoning_result.get('validated_answer', 'Not mentioned')\n",
    "        }\n",
    "        \n",
    "        # Save intermediate results to avoid losing progress\n",
    "        if (i+1) % 10 == 0:\n",
    "            with open(f\"reasoning_results_{i+1}.json\", \"w\") as f:\n",
    "                json.dump(all_results, f, indent=2)\n",
    "            print(f\"Saved intermediate results after processing {i+1} pairs\")\n",
    "    \n",
    "    # Save full results\n",
    "    with open(\"final_reasoning_results.json\", \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Processed all {len(all_pairs)} encounter-question pairs with reasoning layer\")\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd3ecc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reasoning_results_for_eval(all_results, output_file):\n",
    "    \"\"\"\n",
    "    Format results from reasoning layer for official evaluation.\n",
    "    \n",
    "    Args:\n",
    "        all_results: Dictionary with all results from reasoning layer\n",
    "        output_file: Path to save the formatted results\n",
    "    \n",
    "    Returns:\n",
    "        List of formatted predictions for evaluation\n",
    "    \"\"\"\n",
    "    # Define the question IDs and their allowed variants\n",
    "    QIDS = [\n",
    "        \"CQID010-001\",  # how much of body is affected (single answer)\n",
    "        \"CQID011-001\", \"CQID011-002\", \"CQID011-003\", \"CQID011-004\", \"CQID011-005\", \"CQID011-006\",  # multiple answers allowed\n",
    "        \"CQID012-001\", \"CQID012-002\", \"CQID012-003\", \"CQID012-004\", \"CQID012-005\", \"CQID012-006\",  # multiple answers allowed\n",
    "        \"CQID015-001\",  # single answer\n",
    "        \"CQID020-001\", \"CQID020-002\", \"CQID020-003\", \"CQID020-004\", \"CQID020-005\", \n",
    "        \"CQID020-006\", \"CQID020-007\", \"CQID020-008\", \"CQID020-009\",  # multiple answers allowed\n",
    "        \"CQID025-001\",  # single answer\n",
    "        \"CQID034-001\",  # single answer\n",
    "        \"CQID035-001\",  # single answer\n",
    "        \"CQID036-001\",  # single answer\n",
    "    ]\n",
    "    \n",
    "    # Create a mapping of question base IDs to their allowed variants\n",
    "    qid_variants = {}\n",
    "    for qid in QIDS:\n",
    "        base_qid, variant = qid.split('-')\n",
    "        if base_qid not in qid_variants:\n",
    "            qid_variants[base_qid] = []\n",
    "        qid_variants[base_qid].append(qid)\n",
    "    \n",
    "    # Get all required base QIDs for a complete encounter\n",
    "    required_base_qids = set(qid.split('-')[0] for qid in QIDS)\n",
    "    \n",
    "    # Process each encounter\n",
    "    formatted_predictions = []\n",
    "    for encounter_id, questions in all_results.items():\n",
    "        # Check if encounter has all required questions\n",
    "        encounter_base_qids = set(questions.keys())\n",
    "        if not required_base_qids.issubset(encounter_base_qids):\n",
    "            print(f\"Skipping encounter {encounter_id} - missing required questions\")\n",
    "            continue\n",
    "        \n",
    "        # Create prediction entry for this encounter\n",
    "        pred_entry = {'encounter_id': encounter_id}\n",
    "        \n",
    "        # Process each question\n",
    "        for base_qid, question_data in questions.items():\n",
    "            # Skip if no variants defined\n",
    "            if base_qid not in qid_variants:\n",
    "                continue\n",
    "            \n",
    "            # Get final answer from reasoning layer\n",
    "            final_answer = question_data['final_answer']\n",
    "            \n",
    "            # Get options for this question\n",
    "            options = question_data['options']\n",
    "            \n",
    "            # Find \"Not mentioned\" index\n",
    "            not_mentioned_index = None\n",
    "            for i, opt in enumerate(options):\n",
    "                if opt.lower() == \"not mentioned\":\n",
    "                    not_mentioned_index = i\n",
    "                    break\n",
    "            \n",
    "            # Default to last option if \"Not mentioned\" not found\n",
    "            if not_mentioned_index is None:\n",
    "                not_mentioned_index = len(options) - 1\n",
    "            \n",
    "            # Process answer(s)\n",
    "            if ',' in final_answer:\n",
    "                # Multiple answers\n",
    "                answer_parts = [part.strip() for part in final_answer.split(',')]\n",
    "                answer_indices = []\n",
    "                \n",
    "                for part in answer_parts:\n",
    "                    found = False\n",
    "                    for i, opt in enumerate(options):\n",
    "                        if part.lower() == opt.lower():\n",
    "                            answer_indices.append(i)\n",
    "                            found = True\n",
    "                            break\n",
    "                    \n",
    "                    if not found:\n",
    "                        # Default to \"Not mentioned\" if answer not found\n",
    "                        answer_indices.append(not_mentioned_index)\n",
    "                \n",
    "                # Distribute across variants\n",
    "                available_variants = qid_variants[base_qid]\n",
    "                \n",
    "                # Distribute answers across available variants\n",
    "                for i, idx in enumerate(answer_indices):\n",
    "                    if i < len(available_variants):\n",
    "                        pred_entry[available_variants[i]] = idx\n",
    "                \n",
    "                # Fill remaining variants with \"Not mentioned\"\n",
    "                for i in range(len(answer_indices), len(available_variants)):\n",
    "                    pred_entry[available_variants[i]] = not_mentioned_index\n",
    "                \n",
    "            else:\n",
    "                # Single answer\n",
    "                found = False\n",
    "                answer_index = not_mentioned_index\n",
    "                \n",
    "                for i, opt in enumerate(options):\n",
    "                    if final_answer.lower() == opt.lower():\n",
    "                        answer_index = i\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                # Assign to first variant\n",
    "                pred_entry[qid_variants[base_qid][0]] = answer_index\n",
    "                \n",
    "                # Fill remaining variants with \"Not mentioned\" if this is a multi-variant question\n",
    "                if len(qid_variants[base_qid]) > 1:\n",
    "                    for i in range(1, len(qid_variants[base_qid])):\n",
    "                        pred_entry[qid_variants[base_qid][i]] = not_mentioned_index\n",
    "        \n",
    "        # Add to formatted predictions\n",
    "        formatted_predictions.append(pred_entry)\n",
    "    \n",
    "    # Save to JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(formatted_predictions, f, indent=2)\n",
    "    \n",
    "    print(f\"Formatted predictions saved to {output_file} ({len(formatted_predictions)} complete encounters)\")\n",
    "    return formatted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5225ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the end-to-end pipeline\n",
    "# all_results = process_all_encounters_with_reasoning(agentic_data)\n",
    "\n",
    "# # Format the results for evaluation\n",
    "# formatted_predictions = format_reasoning_results_for_eval(\n",
    "#     all_results,\n",
    "#     os.path.join(output_dir, f\"data_cvqa_sys_reasoned_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0db5a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_encounter_with_reasoning(agentic_data, target_encounter_id):\n",
    "    \"\"\"\n",
    "    Process a single encounter with all its questions using the reasoning layer.\n",
    "    \n",
    "    Args:\n",
    "        agentic_data: AgenticRAGData instance containing all encounter data\n",
    "        target_encounter_id: The specific encounter ID to process\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with all questions processed with reasoning for this encounter\n",
    "    \"\"\"\n",
    "    # Get all pairs for this encounter\n",
    "    all_pairs = agentic_data.get_all_encounter_question_pairs()\n",
    "    encounter_pairs = [pair for pair in all_pairs if pair[0] == target_encounter_id]\n",
    "    \n",
    "    if not encounter_pairs:\n",
    "        print(f\"No data found for encounter {target_encounter_id}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Processing {len(encounter_pairs)} questions for encounter {target_encounter_id}\")\n",
    "    \n",
    "    # Dictionary to store all results for this encounter\n",
    "    encounter_results = {target_encounter_id: {}}\n",
    "    \n",
    "    # Get or compute image analysis once for this encounter\n",
    "    print(f\"Computing image analysis for {target_encounter_id}\")\n",
    "    sample_data = agentic_data.get_combined_data(encounter_pairs[0][0], encounter_pairs[0][1])\n",
    "    image_analysis = extract_structured_dermatological_analysis(sample_data)\n",
    "    \n",
    "    # Get or compute clinical context once for this encounter\n",
    "    print(f\"Computing clinical context for {target_encounter_id}\")\n",
    "    clinical_context = extract_clinical_context(sample_data)\n",
    "    \n",
    "    # Process each question for this encounter\n",
    "    for i, (encounter_id, base_qid) in enumerate(encounter_pairs):\n",
    "        print(f\"Processing question {i+1}/{len(encounter_pairs)}: {base_qid}\")\n",
    "        \n",
    "        # Get the combined data for this question\n",
    "        sample_data = agentic_data.get_combined_data(encounter_id, base_qid)\n",
    "        if not sample_data:\n",
    "            print(f\"Warning: No data found for {encounter_id}, {base_qid}\")\n",
    "            continue\n",
    "        \n",
    "        # Apply reasoning layer\n",
    "        print(f\"Applying reasoning layer for {encounter_id}, {base_qid}\")\n",
    "        reasoning_result = apply_reasoning_layer(\n",
    "            encounter_id,\n",
    "            base_qid,\n",
    "            image_analysis,\n",
    "            clinical_context,\n",
    "            sample_data\n",
    "        )\n",
    "        \n",
    "        # Store the result\n",
    "        encounter_results[encounter_id][base_qid] = {\n",
    "            \"query_context\": sample_data['query_context'],\n",
    "            \"options\": sample_data['options'],\n",
    "            \"model_predictions\": sample_data['model_predictions'],\n",
    "            \"reasoning_result\": reasoning_result,\n",
    "            \"final_answer\": reasoning_result.get('validated_answer', 'Not mentioned')\n",
    "        }\n",
    "    \n",
    "    # Save results for this encounter\n",
    "    with open(f\"reasoning_results_{target_encounter_id}.json\", \"w\") as f:\n",
    "        json.dump(encounter_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Processed all {len(encounter_pairs)} questions for encounter {target_encounter_id}\")\n",
    "    return encounter_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f6c74ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9 questions for encounter ENC00852\n",
      "Computing image analysis for ENC00852\n",
      "Analyzing image 1/2 for encounter ENC00852\n",
      "Analysis text received (length: 1655)\n",
      "Successfully parsed structured analysis for image 1\n",
      "Analyzing image 2/2 for encounter ENC00852\n",
      "Analysis text received (length: 1669)\n",
      "Successfully parsed structured analysis for image 2\n",
      "Aggregating 2 valid structured analyses for encounter ENC00852\n",
      "Aggregated analysis received (length: 2581)\n",
      "Successfully parsed aggregated analysis\n",
      "Computing clinical context for ENC00852\n",
      "Processing question 1/9: CQID010\n",
      "Applying reasoning layer for ENC00852, CQID010\n",
      "question_text:  How much of the body is affected?\n",
      "options:  ['single spot', 'limited area', 'widespread', 'Not mentioned']\n",
      "question_type:  Site\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': nan, 'unique_predictions': [''], 'all_raw_predictions': ['', ''], 'all_sorted_predictions': [('', 2)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'limited area', 'unique_predictions': ['limited area'], 'all_raw_predictions': ['limited area', 'Not mentioned'], 'all_sorted_predictions': [('limited area', 1), ('not mentioned', 1)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'limited area', 'unique_predictions': ['limited area'], 'all_raw_predictions': ['limited area', 'widespread'], 'all_sorted_predictions': [('limited area', 1), ('widespread', 1)]}, 'gemma-3-4b-it': {'combined_prediction': 'limited area', 'unique_predictions': ['limited area'], 'all_raw_predictions': ['limited area', 'Back of the hand'], 'all_sorted_predictions': [('limited area', 1), ('back of the hand', 1)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['widespread', 'Not mentioned', 'Not mentioned'], 'all_sorted_predictions': [('not mentioned', 2), ('widespread', 1)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'widespread', 'unique_predictions': ['widespread'], 'all_raw_predictions': ['widespread', 'limited area'], 'all_sorted_predictions': [('widespread', 1), ('limited area', 1)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'limited area', 'unique_predictions': ['limited area'], 'all_raw_predictions': ['limited area', 'limited area'], 'all_sorted_predictions': [('limited area', 2)]}}\n",
      "- gemma-3-12b-it: No prediction\n",
      "- Qwen2-VL-7B-Instruct: limited area\n",
      "- Qwen2-VL-2B-Instruct: limited area\n",
      "- gemma-3-4b-it: limited area\n",
      "- Llama-3.2-11B-Vision-Instruct: not mentioned\n",
      "- Qwen2.5-VL-7B-Instruct: widespread\n",
      "- Qwen2.5-VL-3B-Instruct: limited area\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: How much of the body is affected?\n",
      "    QUESTION TYPE: Site\n",
      "    OPTIONS: single spot, limited area, widespread, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: No prediction\n",
      "- Qwen2-VL-7B-Instruct: limited area\n",
      "- Qwen2-VL-2B-Instruct: limited area\n",
      "- gemma-3-4b-it: limited area\n",
      "- Llama-3.2-11B-Vision-Instruct: not mentioned\n",
      "- Qwen2.5-VL-7B-Instruct: widespread\n",
      "- Qwen2.5-VL-3B-Instruct: limited area\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n",
      "reasoning_text:  ```json\n",
      "{\n",
      "  \"reasoning\": \"The image analysis shows two distinct lesions on the hand, but explicitly states that the 'full extent on the hand or body cannot be determined from either image'. However, the clinical context provides critical information regarding the extent of the condition. It mentions 'Multiple' lesions initially localized to the 'Back of the hand' and 'later appearing on the face'. Furthermore, it states the condition is 'becoming more widespread over time'. Based on the clinical context describing lesions on both the hand and face and the description of the condition becoming more widespread, the most accurate answer is 'widespread'. While the images themselves only show a limited area, the question asks about the extent on the body, which is clearly addressed by the clinical information.\",\n",
      "  \"answer\": \"widespread\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      "  \"reasoning\": \"The image analysis shows two distinct lesions on the hand, but explicitly states that the 'full extent on the hand or body cannot be determined from either image'. However, the clinical context provides critical information regarding the extent of the condition. It mentions 'Multiple' lesions initially localized to the 'Back of the hand' and 'later appearing on the face'. Furthermore, it states the condition is 'becoming more widespread over time'. Based on the clinical context describing lesions on both the hand and face and the description of the condition becoming more widespread, the most accurate answer is 'widespread'. While the images themselves only show a limited area, the question asks about the extent on the body, which is clearly addressed by the clinical information.\",\n",
      "  \"answer\": \"widespread\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID010\n",
      "reasoning_result:  {'reasoning': \"The image analysis shows two distinct lesions on the hand, but explicitly states that the 'full extent on the hand or body cannot be determined from either image'. However, the clinical context provides critical information regarding the extent of the condition. It mentions 'Multiple' lesions initially localized to the 'Back of the hand' and 'later appearing on the face'. Furthermore, it states the condition is 'becoming more widespread over time'. Based on the clinical context describing lesions on both the hand and face and the description of the condition becoming more widespread, the most accurate answer is 'widespread'. While the images themselves only show a limited area, the question asks about the extent on the body, which is clearly addressed by the clinical information.\", 'answer': 'widespread'}\n",
      "answer:  widespread\n",
      "reasoning_result:  {'reasoning': \"The image analysis shows two distinct lesions on the hand, but explicitly states that the 'full extent on the hand or body cannot be determined from either image'. However, the clinical context provides critical information regarding the extent of the condition. It mentions 'Multiple' lesions initially localized to the 'Back of the hand' and 'later appearing on the face'. Furthermore, it states the condition is 'becoming more widespread over time'. Based on the clinical context describing lesions on both the hand and face and the description of the condition becoming more widespread, the most accurate answer is 'widespread'. While the images themselves only show a limited area, the question asks about the extent on the body, which is clearly addressed by the clinical information.\", 'answer': 'widespread', 'validated_answer': 'widespread'}\n",
      "Processing question 2/9: CQID011\n",
      "Applying reasoning layer for ENC00852, CQID011\n",
      "question_text:  Where is the affected area?\n",
      "options:  ['head', 'neck', 'upper extremities', 'lower extremities', 'chest/abdomen', 'back', 'other', 'Not mentioned']\n",
      "question_type:  Site Location\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': 'face, upper extremities, back of the hand', 'unique_predictions': ['face', 'upper extremities', 'back of the hand'], 'all_raw_predictions': ['back of the hand', 'face', 'upper extremities', 'upper extremities', 'face'], 'all_sorted_predictions': [('face', 2), ('upper extremities', 2), ('back of the hand', 1)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'upper extremities, back', 'unique_predictions': ['upper extremities', 'back'], 'all_raw_predictions': ['upper extremities', 'back', 'upper extremities'], 'all_sorted_predictions': [('upper extremities', 2), ('back', 1)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'back', 'unique_predictions': ['back'], 'all_raw_predictions': ['back', 'back'], 'all_sorted_predictions': [('back', 2)]}, 'gemma-3-4b-it': {'combined_prediction': 'back, upper extremities', 'unique_predictions': ['back', 'upper extremities'], 'all_raw_predictions': ['back', 'upper extremities', 'back', 'upper extremities'], 'all_sorted_predictions': [('back', 2), ('upper extremities', 2)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'upper extremities, back, lower extremities, other', 'unique_predictions': ['upper extremities', 'back', 'lower extremities', 'other'], 'all_raw_predictions': ['upper extremities', 'Not mentioned', 'Back', 'lower extremities', 'other'], 'all_sorted_predictions': [('upper extremities', 1), ('not mentioned', 1), ('back', 1), ('lower extremities', 1), ('other', 1)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'back, upper extremities', 'unique_predictions': ['back', 'upper extremities'], 'all_raw_predictions': ['back', 'upper extremities', 'back'], 'all_sorted_predictions': [('back', 2), ('upper extremities', 1)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'back', 'unique_predictions': ['back'], 'all_raw_predictions': ['back', 'back'], 'all_sorted_predictions': [('back', 2)]}}\n",
      "- gemma-3-12b-it: face, upper extremities, back of the hand\n",
      "- Qwen2-VL-7B-Instruct: upper extremities, back\n",
      "- Qwen2-VL-2B-Instruct: back\n",
      "- gemma-3-4b-it: back, upper extremities\n",
      "- Llama-3.2-11B-Vision-Instruct: upper extremities, back, lower extremities, other\n",
      "- Qwen2.5-VL-7B-Instruct: back, upper extremities\n",
      "- Qwen2.5-VL-3B-Instruct: back\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: Where is the affected area?\n",
      "    QUESTION TYPE: Site Location\n",
      "    OPTIONS: head, neck, upper extremities, lower extremities, chest/abdomen, back, other, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: face, upper extremities, back of the hand\n",
      "- Qwen2-VL-7B-Instruct: upper extremities, back\n",
      "- Qwen2-VL-2B-Instruct: back\n",
      "- gemma-3-4b-it: back, upper extremities\n",
      "- Llama-3.2-11B-Vision-Instruct: upper extremities, back, lower extremities, other\n",
      "- Qwen2.5-VL-7B-Instruct: back, upper extremities\n",
      "- Qwen2.5-VL-3B-Instruct: back\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_text:  ```json\n",
      "{\n",
      "  \"reasoning\": \"The image analysis explicitly states that lesions are located on the 'dorsum of the hand', which falls under the 'upper extremities' category. The clinical context confirms involvement of the 'Back of the hand' (upper extremities) and explicitly mentions lesions on the 'Face', which falls under the 'head' category. The clinical context also notes the condition is becoming more widespread, but does not specify other locations from the given options. Therefore, based directly on the provided evidence, the affected areas are the head and upper extremities.\",\n",
      "  \"answer\": \"head, upper extremities\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      "  \"reasoning\": \"The image analysis explicitly states that lesions are located on the 'dorsum of the hand', which falls under the 'upper extremities' category. The clinical context confirms involvement of the 'Back of the hand' (upper extremities) and explicitly mentions lesions on the 'Face', which falls under the 'head' category. The clinical context also notes the condition is becoming more widespread, but does not specify other locations from the given options. Therefore, based directly on the provided evidence, the affected areas are the head and upper extremities.\",\n",
      "  \"answer\": \"head, upper extremities\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID011\n",
      "reasoning_result:  {'reasoning': \"The image analysis explicitly states that lesions are located on the 'dorsum of the hand', which falls under the 'upper extremities' category. The clinical context confirms involvement of the 'Back of the hand' (upper extremities) and explicitly mentions lesions on the 'Face', which falls under the 'head' category. The clinical context also notes the condition is becoming more widespread, but does not specify other locations from the given options. Therefore, based directly on the provided evidence, the affected areas are the head and upper extremities.\", 'answer': 'head, upper extremities'}\n",
      "answer:  head, upper extremities\n",
      "reasoning_result:  {'reasoning': \"The image analysis explicitly states that lesions are located on the 'dorsum of the hand', which falls under the 'upper extremities' category. The clinical context confirms involvement of the 'Back of the hand' (upper extremities) and explicitly mentions lesions on the 'Face', which falls under the 'head' category. The clinical context also notes the condition is becoming more widespread, but does not specify other locations from the given options. Therefore, based directly on the provided evidence, the affected areas are the head and upper extremities.\", 'answer': 'head, upper extremities', 'validated_answer': 'head, upper extremities'}\n",
      "Processing question 3/9: CQID012\n",
      "Applying reasoning layer for ENC00852, CQID012\n",
      "question_text:  How large are the affected areas?\n",
      "options:  ['size of thumb nail', 'size of palm', 'larger area', 'Not mentioned']\n",
      "question_type:  Size\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': 'larger area', 'unique_predictions': ['larger area'], 'all_raw_predictions': ['larger area', 'larger area'], 'all_sorted_predictions': [('larger area', 2)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'size of palm, larger area', 'unique_predictions': ['size of palm', 'larger area'], 'all_raw_predictions': ['size of palm', 'larger area', 'size of palm', 'larger area'], 'all_sorted_predictions': [('size of palm', 2), ('larger area', 2)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'Not mentioned'], 'all_sorted_predictions': [('not mentioned', 2)]}, 'gemma-3-4b-it': {'combined_prediction': 'larger area', 'unique_predictions': ['larger area'], 'all_raw_predictions': ['larger area', 'Not mentioned'], 'all_sorted_predictions': [('larger area', 1), ('not mentioned', 1)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'lager area, larger area', 'unique_predictions': ['lager area', 'larger area'], 'all_raw_predictions': ['lager area', 'Larger area'], 'all_sorted_predictions': [('lager area', 1), ('larger area', 1)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'size of palm, larger area', 'unique_predictions': ['size of palm', 'larger area'], 'all_raw_predictions': ['size of palm', 'size of palm', 'larger area'], 'all_sorted_predictions': [('size of palm', 2), ('larger area', 1)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'larger area', 'unique_predictions': ['larger area'], 'all_raw_predictions': ['Larger area', 'larger area'], 'all_sorted_predictions': [('larger area', 2)]}}\n",
      "- gemma-3-12b-it: larger area\n",
      "- Qwen2-VL-7B-Instruct: size of palm, larger area\n",
      "- Qwen2-VL-2B-Instruct: not mentioned\n",
      "- gemma-3-4b-it: larger area\n",
      "- Llama-3.2-11B-Vision-Instruct: lager area, larger area\n",
      "- Qwen2.5-VL-7B-Instruct: size of palm, larger area\n",
      "- Qwen2.5-VL-3B-Instruct: larger area\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: How large are the affected areas?\n",
      "    QUESTION TYPE: Size\n",
      "    OPTIONS: size of thumb nail, size of palm, larger area, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: larger area\n",
      "- Qwen2-VL-7B-Instruct: size of palm, larger area\n",
      "- Qwen2-VL-2B-Instruct: not mentioned\n",
      "- gemma-3-4b-it: larger area\n",
      "- Llama-3.2-11B-Vision-Instruct: lager area, larger area\n",
      "- Qwen2.5-VL-7B-Instruct: size of palm, larger area\n",
      "- Qwen2.5-VL-3B-Instruct: larger area\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_text:  ```json\n",
      "{\n",
      " \"reasoning\": \"The image analysis states that the visible lesions on the hand are small, approximately 5-10 mm, and smaller than a thumbnail. However, the clinical context provides additional information about the progression of the condition. It mentions that the 'Rashes are getting bigger' and becoming 'more widespread over time', affecting the hands and later the face. The question asks about the size of the affected areas, which, in light of the clinical history, refers not just to the current size of the depicted macules but to the overall extent and growth of the condition. The description 'getting bigger' and 'more widespread' indicates that the affected areas are expanding, fitting the description of a 'larger area' compared to the initial presentation or the size of the individual small lesions shown. While individual lesions might be small, the condition as a whole involves a larger or growing area. The option 'size of palm' is not explicitly mentioned for any specific lesion or the total area. The option 'larger area' aligns best with the clinical history of the condition worsening in size and extent.\",\n",
      " \"answer\": \"larger area\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      " \"reasoning\": \"The image analysis states that the visible lesions on the hand are small, approximately 5-10 mm, and smaller than a thumbnail. However, the clinical context provides additional information about the progression of the condition. It mentions that the 'Rashes are getting bigger' and becoming 'more widespread over time', affecting the hands and later the face. The question asks about the size of the affected areas, which, in light of the clinical history, refers not just to the current size of the depicted macules but to the overall extent and growth of the condition. The description 'getting bigger' and 'more widespread' indicates that the affected areas are expanding, fitting the description of a 'larger area' compared to the initial presentation or the size of the individual small lesions shown. While individual lesions might be small, the condition as a whole involves a larger or growing area. The option 'size of palm' is not explicitly mentioned for any specific lesion or the total area. The option 'larger area' aligns best with the clinical history of the condition worsening in size and extent.\",\n",
      " \"answer\": \"larger area\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID012\n",
      "reasoning_result:  {'reasoning': \"The image analysis states that the visible lesions on the hand are small, approximately 5-10 mm, and smaller than a thumbnail. However, the clinical context provides additional information about the progression of the condition. It mentions that the 'Rashes are getting bigger' and becoming 'more widespread over time', affecting the hands and later the face. The question asks about the size of the affected areas, which, in light of the clinical history, refers not just to the current size of the depicted macules but to the overall extent and growth of the condition. The description 'getting bigger' and 'more widespread' indicates that the affected areas are expanding, fitting the description of a 'larger area' compared to the initial presentation or the size of the individual small lesions shown. While individual lesions might be small, the condition as a whole involves a larger or growing area. The option 'size of palm' is not explicitly mentioned for any specific lesion or the total area. The option 'larger area' aligns best with the clinical history of the condition worsening in size and extent.\", 'answer': 'larger area'}\n",
      "answer:  larger area\n",
      "reasoning_result:  {'reasoning': \"The image analysis states that the visible lesions on the hand are small, approximately 5-10 mm, and smaller than a thumbnail. However, the clinical context provides additional information about the progression of the condition. It mentions that the 'Rashes are getting bigger' and becoming 'more widespread over time', affecting the hands and later the face. The question asks about the size of the affected areas, which, in light of the clinical history, refers not just to the current size of the depicted macules but to the overall extent and growth of the condition. The description 'getting bigger' and 'more widespread' indicates that the affected areas are expanding, fitting the description of a 'larger area' compared to the initial presentation or the size of the individual small lesions shown. While individual lesions might be small, the condition as a whole involves a larger or growing area. The option 'size of palm' is not explicitly mentioned for any specific lesion or the total area. The option 'larger area' aligns best with the clinical history of the condition worsening in size and extent.\", 'answer': 'larger area', 'validated_answer': 'larger area'}\n",
      "Processing question 4/9: CQID015\n",
      "Applying reasoning layer for ENC00852, CQID015\n",
      "question_text:  When did the patient first notice the issue?\n",
      "options:  ['within hours', 'within days', 'within weeks', 'within months', 'over a year', 'multiple years', 'Not mentioned']\n",
      "question_type:  Onset\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': 'within months', 'unique_predictions': ['within months'], 'all_raw_predictions': ['within months', 'within months'], 'all_sorted_predictions': [('within months', 2)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'Not mentioned'], 'all_sorted_predictions': [('not mentioned', 2)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'Not mentioned'], 'all_sorted_predictions': [('not mentioned', 2)]}, 'gemma-3-4b-it': {'combined_prediction': 'within months', 'unique_predictions': ['within months'], 'all_raw_predictions': ['within weeks', 'within days', 'within months'], 'all_sorted_predictions': [('within weeks', 1), ('within days', 1), ('within months', 1)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'within weeks', 'unique_predictions': ['within weeks'], 'all_raw_predictions': ['within months', 'multiple years', 'within weeks'], 'all_sorted_predictions': [('within months', 1), ('multiple years', 1), ('within weeks', 1)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'within weeks', 'unique_predictions': ['within weeks'], 'all_raw_predictions': ['within weeks', 'Not mentioned'], 'all_sorted_predictions': [('within weeks', 1), ('not mentioned', 1)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'within weeks', 'unique_predictions': ['within weeks'], 'all_raw_predictions': ['within weeks', 'over a year'], 'all_sorted_predictions': [('within weeks', 1), ('over a year', 1)]}}\n",
      "- gemma-3-12b-it: within months\n",
      "- Qwen2-VL-7B-Instruct: not mentioned\n",
      "- Qwen2-VL-2B-Instruct: not mentioned\n",
      "- gemma-3-4b-it: within months\n",
      "- Llama-3.2-11B-Vision-Instruct: within weeks\n",
      "- Qwen2.5-VL-7B-Instruct: within weeks\n",
      "- Qwen2.5-VL-3B-Instruct: within weeks\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: When did the patient first notice the issue?\n",
      "    QUESTION TYPE: Onset\n",
      "    OPTIONS: within hours, within days, within weeks, within months, over a year, multiple years, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: within months\n",
      "- Qwen2-VL-7B-Instruct: not mentioned\n",
      "- Qwen2-VL-2B-Instruct: not mentioned\n",
      "- gemma-3-4b-it: within months\n",
      "- Llama-3.2-11B-Vision-Instruct: within weeks\n",
      "- Qwen2.5-VL-7B-Instruct: within weeks\n",
      "- Qwen2.5-VL-3B-Instruct: within weeks\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_text:  ```json\n",
      "{\n",
      " \"reasoning\": \"The clinical context states, 'Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.' This sentence describes the progression of the issue, starting from the onset on the hand. The most logical interpretation is that the macula appeared on the face one month *after the onset* of the hand lesions. Therefore, the initial onset of the issue on the hand was approximately one month ago. One month falls within the 'within months' timeframe. While the term 'gradually turn into Leukoplakia' and 'getting bigger' also imply a duration longer than days or hours, the specific mention of 'one month later' provides the most concrete timeline anchor relative to the onset.\",\n",
      " \"answer\": \"within months\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      " \"reasoning\": \"The clinical context states, 'Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.' This sentence describes the progression of the issue, starting from the onset on the hand. The most logical interpretation is that the macula appeared on the face one month *after the onset* of the hand lesions. Therefore, the initial onset of the issue on the hand was approximately one month ago. One month falls within the 'within months' timeframe. While the term 'gradually turn into Leukoplakia' and 'getting bigger' also imply a duration longer than days or hours, the specific mention of 'one month later' provides the most concrete timeline anchor relative to the onset.\",\n",
      " \"answer\": \"within months\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID015\n",
      "reasoning_result:  {'reasoning': \"The clinical context states, 'Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.' This sentence describes the progression of the issue, starting from the onset on the hand. The most logical interpretation is that the macula appeared on the face one month *after the onset* of the hand lesions. Therefore, the initial onset of the issue on the hand was approximately one month ago. One month falls within the 'within months' timeframe. While the term 'gradually turn into Leukoplakia' and 'getting bigger' also imply a duration longer than days or hours, the specific mention of 'one month later' provides the most concrete timeline anchor relative to the onset.\", 'answer': 'within months'}\n",
      "answer:  within months\n",
      "reasoning_result:  {'reasoning': \"The clinical context states, 'Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.' This sentence describes the progression of the issue, starting from the onset on the hand. The most logical interpretation is that the macula appeared on the face one month *after the onset* of the hand lesions. Therefore, the initial onset of the issue on the hand was approximately one month ago. One month falls within the 'within months' timeframe. While the term 'gradually turn into Leukoplakia' and 'getting bigger' also imply a duration longer than days or hours, the specific mention of 'one month later' provides the most concrete timeline anchor relative to the onset.\", 'answer': 'within months', 'validated_answer': 'within months'}\n",
      "Processing question 5/9: CQID020\n",
      "Applying reasoning layer for ENC00852, CQID020\n",
      "question_text:  What label best describes the affected area?\n",
      "options:  ['raised or bumpy', 'flat', 'skin loss or sunken', 'thick or raised', 'thin or close to the surface', 'warty', 'crust', 'scab', 'weeping', 'Not mentioned']\n",
      "question_type:  Skin Description\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': 'flat, thin or close to the surface', 'unique_predictions': ['flat', 'thin or close to the surface'], 'all_raw_predictions': ['flat', 'thin or close to the surface', 'flat'], 'all_sorted_predictions': [('flat', 2), ('thin or close to the surface', 1)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'raised or bumpy', 'unique_predictions': ['raised or bumpy'], 'all_raw_predictions': ['raised or bumpy', 'raised or bumpy'], 'all_sorted_predictions': [('raised or bumpy', 2)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'skin loss or sunken', 'unique_predictions': ['skin loss or sunken'], 'all_raw_predictions': ['Skin loss or sunken', 'Skin loss or sunken'], 'all_sorted_predictions': [('skin loss or sunken', 2)]}, 'gemma-3-4b-it': {'combined_prediction': 'flat, raised or bumpy, thin or close to the surface', 'unique_predictions': ['flat', 'raised or bumpy', 'thin or close to the surface'], 'all_raw_predictions': ['flat', 'raised or bumpy', 'flat', 'thin or close to the surface'], 'all_sorted_predictions': [('flat', 2), ('raised or bumpy', 1), ('thin or close to the surface', 1)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'thick or raised, raised or bumpy, scab', 'unique_predictions': ['thick or raised', 'raised or bumpy', 'scab'], 'all_raw_predictions': ['thick or raised', 'raised or bumpy', 'scab'], 'all_sorted_predictions': [('thick or raised', 1), ('raised or bumpy', 1), ('scab', 1)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'raised or bumpy', 'unique_predictions': ['raised or bumpy'], 'all_raw_predictions': ['raised or bumpy', 'Not mentioned'], 'all_sorted_predictions': [('raised or bumpy', 1), ('not mentioned', 1)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'thin or close to the surface, thick or raised', 'unique_predictions': ['thin or close to the surface', 'thick or raised'], 'all_raw_predictions': ['thin or close to the surface', 'thick or raised'], 'all_sorted_predictions': [('thin or close to the surface', 1), ('thick or raised', 1)]}}\n",
      "- gemma-3-12b-it: flat, thin or close to the surface\n",
      "- Qwen2-VL-7B-Instruct: raised or bumpy\n",
      "- Qwen2-VL-2B-Instruct: skin loss or sunken\n",
      "- gemma-3-4b-it: flat, raised or bumpy, thin or close to the surface\n",
      "- Llama-3.2-11B-Vision-Instruct: thick or raised, raised or bumpy, scab\n",
      "- Qwen2.5-VL-7B-Instruct: raised or bumpy\n",
      "- Qwen2.5-VL-3B-Instruct: thin or close to the surface, thick or raised\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: What label best describes the affected area?\n",
      "    QUESTION TYPE: Skin Description\n",
      "    OPTIONS: raised or bumpy, flat, skin loss or sunken, thick or raised, thin or close to the surface, warty, crust, scab, weeping, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: flat, thin or close to the surface\n",
      "- Qwen2-VL-7B-Instruct: raised or bumpy\n",
      "- Qwen2-VL-2B-Instruct: skin loss or sunken\n",
      "- gemma-3-4b-it: flat, raised or bumpy, thin or close to the surface\n",
      "- Llama-3.2-11B-Vision-Instruct: thick or raised, raised or bumpy, scab\n",
      "- Qwen2.5-VL-7B-Instruct: raised or bumpy\n",
      "- Qwen2.5-VL-3B-Instruct: thin or close to the surface, thick or raised\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_text:  ```json\n",
      "{\n",
      " \"reasoning\": \"The question asks for the best label to describe the affected area. The image analysis explicitly states that 'The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface'. The clinical context also mentions 'Macula (flat spots) on the face'. Both sources describe the lesions as 'flat' or 'macular', which means flat. The options include 'flat'. Other options like 'raised or bumpy', 'skin loss or sunken', 'thick or raised', 'warty', 'crust', 'scab', and 'weeping' are either directly contradicted by the image analysis ('No scales or crust') or not supported by the evidence. The option 'thin or close to the surface' could potentially apply to a macule (as there is no thickening), but 'flat' is the primary descriptor used in both sources to describe the elevation relative to surrounding skin, which is the distinguishing feature of a macule compared to raised or sunken lesions. Therefore, 'flat' is the most accurate description based on the provided evidence.\",\n",
      " \"answer\": \"flat\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      " \"reasoning\": \"The question asks for the best label to describe the affected area. The image analysis explicitly states that 'The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface'. The clinical context also mentions 'Macula (flat spots) on the face'. Both sources describe the lesions as 'flat' or 'macular', which means flat. The options include 'flat'. Other options like 'raised or bumpy', 'skin loss or sunken', 'thick or raised', 'warty', 'crust', 'scab', and 'weeping' are either directly contradicted by the image analysis ('No scales or crust') or not supported by the evidence. The option 'thin or close to the surface' could potentially apply to a macule (as there is no thickening), but 'flat' is the primary descriptor used in both sources to describe the elevation relative to surrounding skin, which is the distinguishing feature of a macule compared to raised or sunken lesions. Therefore, 'flat' is the most accurate description based on the provided evidence.\",\n",
      " \"answer\": \"flat\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID020\n",
      "reasoning_result:  {'reasoning': \"The question asks for the best label to describe the affected area. The image analysis explicitly states that 'The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface'. The clinical context also mentions 'Macula (flat spots) on the face'. Both sources describe the lesions as 'flat' or 'macular', which means flat. The options include 'flat'. Other options like 'raised or bumpy', 'skin loss or sunken', 'thick or raised', 'warty', 'crust', 'scab', and 'weeping' are either directly contradicted by the image analysis ('No scales or crust') or not supported by the evidence. The option 'thin or close to the surface' could potentially apply to a macule (as there is no thickening), but 'flat' is the primary descriptor used in both sources to describe the elevation relative to surrounding skin, which is the distinguishing feature of a macule compared to raised or sunken lesions. Therefore, 'flat' is the most accurate description based on the provided evidence.\", 'answer': 'flat'}\n",
      "answer:  flat\n",
      "reasoning_result:  {'reasoning': \"The question asks for the best label to describe the affected area. The image analysis explicitly states that 'The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface'. The clinical context also mentions 'Macula (flat spots) on the face'. Both sources describe the lesions as 'flat' or 'macular', which means flat. The options include 'flat'. Other options like 'raised or bumpy', 'skin loss or sunken', 'thick or raised', 'warty', 'crust', 'scab', and 'weeping' are either directly contradicted by the image analysis ('No scales or crust') or not supported by the evidence. The option 'thin or close to the surface' could potentially apply to a macule (as there is no thickening), but 'flat' is the primary descriptor used in both sources to describe the elevation relative to surrounding skin, which is the distinguishing feature of a macule compared to raised or sunken lesions. Therefore, 'flat' is the most accurate description based on the provided evidence.\", 'answer': 'flat', 'validated_answer': 'flat'}\n",
      "Processing question 6/9: CQID025\n",
      "Applying reasoning layer for ENC00852, CQID025\n",
      "question_text:  Is there any associated itching with the skin problem?\n",
      "options:  ['yes', 'no', 'Not mentioned']\n",
      "question_type:  Itch\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': nan, 'unique_predictions': [''], 'all_raw_predictions': ['', ''], 'all_sorted_predictions': [('', 2)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'no', 'unique_predictions': ['no'], 'all_raw_predictions': ['no', 'Not mentioned'], 'all_sorted_predictions': [('no', 1), ('not mentioned', 1)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'yes', 'unique_predictions': ['yes'], 'all_raw_predictions': ['Yes', 'No'], 'all_sorted_predictions': [('yes', 1), ('no', 1)]}, 'gemma-3-4b-it': {'combined_prediction': 'yes', 'unique_predictions': ['yes'], 'all_raw_predictions': ['yes', 'patient feels no specific symptoms'], 'all_sorted_predictions': [('yes', 1), ('patient feels no specific symptoms', 1)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'yes', 'unique_predictions': ['yes'], 'all_raw_predictions': ['yes', 'Not mentioned', 'yes'], 'all_sorted_predictions': [('yes', 2), ('not mentioned', 1)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'No'], 'all_sorted_predictions': [('not mentioned', 1), ('no', 1)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'yes', 'unique_predictions': ['yes'], 'all_raw_predictions': ['yes', 'yes'], 'all_sorted_predictions': [('yes', 2)]}}\n",
      "- gemma-3-12b-it: No prediction\n",
      "- Qwen2-VL-7B-Instruct: no\n",
      "- Qwen2-VL-2B-Instruct: yes\n",
      "- gemma-3-4b-it: yes\n",
      "- Llama-3.2-11B-Vision-Instruct: yes\n",
      "- Qwen2.5-VL-7B-Instruct: not mentioned\n",
      "- Qwen2.5-VL-3B-Instruct: yes\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: Is there any associated itching with the skin problem?\n",
      "    QUESTION TYPE: Itch\n",
      "    OPTIONS: yes, no, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: No prediction\n",
      "- Qwen2-VL-7B-Instruct: no\n",
      "- Qwen2-VL-2B-Instruct: yes\n",
      "- gemma-3-4b-it: yes\n",
      "- Llama-3.2-11B-Vision-Instruct: yes\n",
      "- Qwen2.5-VL-7B-Instruct: not mentioned\n",
      "- Qwen2.5-VL-3B-Instruct: yes\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_text:  ```json\n",
      "{\n",
      "  \"reasoning\": \"The question asks if there is any associated itching with the skin problem. The image analysis notes that itching (pruritus) cannot be determined from the images and finds no visible signs like scratch marks. The clinical context, under the heading 'ITCH_INDICATORS', explicitly states 'None mentioned (Patient feels no specific symptoms)'. This indicates that the patient does not experience itching. Based on the direct statement in the clinical context, the answer is no.\",\n",
      "  \"answer\": \"no\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      "  \"reasoning\": \"The question asks if there is any associated itching with the skin problem. The image analysis notes that itching (pruritus) cannot be determined from the images and finds no visible signs like scratch marks. The clinical context, under the heading 'ITCH_INDICATORS', explicitly states 'None mentioned (Patient feels no specific symptoms)'. This indicates that the patient does not experience itching. Based on the direct statement in the clinical context, the answer is no.\",\n",
      "  \"answer\": \"no\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID025\n",
      "reasoning_result:  {'reasoning': \"The question asks if there is any associated itching with the skin problem. The image analysis notes that itching (pruritus) cannot be determined from the images and finds no visible signs like scratch marks. The clinical context, under the heading 'ITCH_INDICATORS', explicitly states 'None mentioned (Patient feels no specific symptoms)'. This indicates that the patient does not experience itching. Based on the direct statement in the clinical context, the answer is no.\", 'answer': 'no'}\n",
      "answer:  no\n",
      "reasoning_result:  {'reasoning': \"The question asks if there is any associated itching with the skin problem. The image analysis notes that itching (pruritus) cannot be determined from the images and finds no visible signs like scratch marks. The clinical context, under the heading 'ITCH_INDICATORS', explicitly states 'None mentioned (Patient feels no specific symptoms)'. This indicates that the patient does not experience itching. Based on the direct statement in the clinical context, the answer is no.\", 'answer': 'no', 'validated_answer': 'no'}\n",
      "Processing question 7/9: CQID034\n",
      "Applying reasoning layer for ENC00852, CQID034\n",
      "question_text:  Compared to the normal surrounding skin, what is the color of the skin lesion?\n",
      "options:  ['normal skin color', 'pink', 'red', 'brown', 'blue', 'purple', 'black', 'white', 'combination', 'hyperpigmentation', 'hypopigmentation', 'Not mentioned']\n",
      "question_type:  Lesion Color\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': 'combination', 'unique_predictions': ['combination'], 'all_raw_predictions': ['red', 'white', 'combination', 'red', 'white', 'combination', 'hypopigmentation'], 'all_sorted_predictions': [('red', 2), ('white', 2), ('combination', 2), ('hypopigmentation', 1)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'normal skin color'], 'all_sorted_predictions': [('not mentioned', 1), ('normal skin color', 1)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'Not mentioned'], 'all_sorted_predictions': [('not mentioned', 2)]}, 'gemma-3-4b-it': {'combined_prediction': 'white', 'unique_predictions': ['white'], 'all_raw_predictions': ['white', 'red', 'red', 'white'], 'all_sorted_predictions': [('white', 2), ('red', 2)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'red', 'unique_predictions': ['red'], 'all_raw_predictions': ['red', 'red'], 'all_sorted_predictions': [('red', 2)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'white', 'unique_predictions': ['white'], 'all_raw_predictions': ['white', 'normal skin color'], 'all_sorted_predictions': [('white', 1), ('normal skin color', 1)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['white', 'hypopigmentation', 'Not mentioned'], 'all_sorted_predictions': [('white', 1), ('hypopigmentation', 1), ('not mentioned', 1)]}}\n",
      "- gemma-3-12b-it: combination\n",
      "- Qwen2-VL-7B-Instruct: not mentioned\n",
      "- Qwen2-VL-2B-Instruct: not mentioned\n",
      "- gemma-3-4b-it: white\n",
      "- Llama-3.2-11B-Vision-Instruct: red\n",
      "- Qwen2.5-VL-7B-Instruct: white\n",
      "- Qwen2.5-VL-3B-Instruct: not mentioned\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: Compared to the normal surrounding skin, what is the color of the skin lesion?\n",
      "    QUESTION TYPE: Lesion Color\n",
      "    OPTIONS: normal skin color, pink, red, brown, blue, purple, black, white, combination, hyperpigmentation, hypopigmentation, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: combination\n",
      "- Qwen2-VL-7B-Instruct: not mentioned\n",
      "- Qwen2-VL-2B-Instruct: not mentioned\n",
      "- gemma-3-4b-it: white\n",
      "- Llama-3.2-11B-Vision-Instruct: red\n",
      "- Qwen2.5-VL-7B-Instruct: white\n",
      "- Qwen2.5-VL-3B-Instruct: not mentioned\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_text:  ```json\n",
      "{\n",
      "  \"reasoning\": \"The image analysis explicitly states that the lesions on the hand are 'hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin.' This description directly answers the question 'Compared to the normal surrounding skin, what is the color of the skin lesion?' by stating they are 'hypopigmented' and describing their appearance as 'whitish'. The clinical context also mentions the rashes gradually turn into 'Leukoplakia (whitish/hypopigmented patches)'. Both the terms 'white' and 'hypopigmentation' are among the provided options and are directly supported by the evidence.\",\n",
      "  \"answer\": \"white, hypopigmentation\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      "  \"reasoning\": \"The image analysis explicitly states that the lesions on the hand are 'hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin.' This description directly answers the question 'Compared to the normal surrounding skin, what is the color of the skin lesion?' by stating they are 'hypopigmented' and describing their appearance as 'whitish'. The clinical context also mentions the rashes gradually turn into 'Leukoplakia (whitish/hypopigmented patches)'. Both the terms 'white' and 'hypopigmentation' are among the provided options and are directly supported by the evidence.\",\n",
      "  \"answer\": \"white, hypopigmentation\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID034\n",
      "reasoning_result:  {'reasoning': \"The image analysis explicitly states that the lesions on the hand are 'hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin.' This description directly answers the question 'Compared to the normal surrounding skin, what is the color of the skin lesion?' by stating they are 'hypopigmented' and describing their appearance as 'whitish'. The clinical context also mentions the rashes gradually turn into 'Leukoplakia (whitish/hypopigmented patches)'. Both the terms 'white' and 'hypopigmentation' are among the provided options and are directly supported by the evidence.\", 'answer': 'white, hypopigmentation'}\n",
      "answer:  white, hypopigmentation\n",
      "reasoning_result:  {'reasoning': \"The image analysis explicitly states that the lesions on the hand are 'hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin.' This description directly answers the question 'Compared to the normal surrounding skin, what is the color of the skin lesion?' by stating they are 'hypopigmented' and describing their appearance as 'whitish'. The clinical context also mentions the rashes gradually turn into 'Leukoplakia (whitish/hypopigmented patches)'. Both the terms 'white' and 'hypopigmentation' are among the provided options and are directly supported by the evidence.\", 'answer': 'white, hypopigmentation', 'validated_answer': 'white, hypopigmentation'}\n",
      "Processing question 8/9: CQID035\n",
      "Applying reasoning layer for ENC00852, CQID035\n",
      "question_text:  How many skin lesions are there?\n",
      "options:  ['single', 'multiple', 'Not mentioned']\n",
      "question_type:  Lesion Count\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': nan, 'unique_predictions': [''], 'all_raw_predictions': ['', 'multiple'], 'all_sorted_predictions': [('', 1), ('multiple', 1)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'multiple', 'unique_predictions': ['multiple'], 'all_raw_predictions': ['Multiple', 'single', 'multiple'], 'all_sorted_predictions': [('multiple', 2), ('single', 1)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'Not mentioned'], 'all_sorted_predictions': [('not mentioned', 2)]}, 'gemma-3-4b-it': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'Not mentioned'], 'all_sorted_predictions': [('not mentioned', 2)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'single', 'unique_predictions': ['single'], 'all_raw_predictions': ['single', 'single'], 'all_sorted_predictions': [('single', 2)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'multiple', 'unique_predictions': ['multiple'], 'all_raw_predictions': ['multiple', 'multiple'], 'all_sorted_predictions': [('multiple', 2)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'multiple', 'unique_predictions': ['multiple'], 'all_raw_predictions': ['multiple', 'single'], 'all_sorted_predictions': [('multiple', 1), ('single', 1)]}}\n",
      "- gemma-3-12b-it: No prediction\n",
      "- Qwen2-VL-7B-Instruct: multiple\n",
      "- Qwen2-VL-2B-Instruct: not mentioned\n",
      "- gemma-3-4b-it: not mentioned\n",
      "- Llama-3.2-11B-Vision-Instruct: single\n",
      "- Qwen2.5-VL-7B-Instruct: multiple\n",
      "- Qwen2.5-VL-3B-Instruct: multiple\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: How many skin lesions are there?\n",
      "    QUESTION TYPE: Lesion Count\n",
      "    OPTIONS: single, multiple, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: No prediction\n",
      "- Qwen2-VL-7B-Instruct: multiple\n",
      "- Qwen2-VL-2B-Instruct: not mentioned\n",
      "- gemma-3-4b-it: not mentioned\n",
      "- Llama-3.2-11B-Vision-Instruct: single\n",
      "- Qwen2.5-VL-7B-Instruct: multiple\n",
      "- Qwen2.5-VL-3B-Instruct: multiple\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_text:  ```json\n",
      "{\n",
      " \"reasoning\": \"The image analysis explicitly states that there are 'Two distinct lesions' visible on the hand in the provided images. The clinical context describes the patient's condition as having 'Multiple (rashes, macula)', initially localized to hands and later appearing on the face, becoming 'more widespread over time'. The question asks 'How many skin lesions are there?'. While the image shows two lesions, the clinical context indicates a broader picture of the patient's condition with multiple lesions overall. The options provided are 'single', 'multiple', and 'Not mentioned'. Since the image shows more than one lesion (two) and the clinical context states 'Multiple', the most accurate answer within the given options is 'multiple'. The majority of the successful model predictions also align with 'multiple'.\",\n",
      " \"answer\": \"multiple\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      " \"reasoning\": \"The image analysis explicitly states that there are 'Two distinct lesions' visible on the hand in the provided images. The clinical context describes the patient's condition as having 'Multiple (rashes, macula)', initially localized to hands and later appearing on the face, becoming 'more widespread over time'. The question asks 'How many skin lesions are there?'. While the image shows two lesions, the clinical context indicates a broader picture of the patient's condition with multiple lesions overall. The options provided are 'single', 'multiple', and 'Not mentioned'. Since the image shows more than one lesion (two) and the clinical context states 'Multiple', the most accurate answer within the given options is 'multiple'. The majority of the successful model predictions also align with 'multiple'.\",\n",
      " \"answer\": \"multiple\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID035\n",
      "reasoning_result:  {'reasoning': \"The image analysis explicitly states that there are 'Two distinct lesions' visible on the hand in the provided images. The clinical context describes the patient's condition as having 'Multiple (rashes, macula)', initially localized to hands and later appearing on the face, becoming 'more widespread over time'. The question asks 'How many skin lesions are there?'. While the image shows two lesions, the clinical context indicates a broader picture of the patient's condition with multiple lesions overall. The options provided are 'single', 'multiple', and 'Not mentioned'. Since the image shows more than one lesion (two) and the clinical context states 'Multiple', the most accurate answer within the given options is 'multiple'. The majority of the successful model predictions also align with 'multiple'.\", 'answer': 'multiple'}\n",
      "answer:  multiple\n",
      "reasoning_result:  {'reasoning': \"The image analysis explicitly states that there are 'Two distinct lesions' visible on the hand in the provided images. The clinical context describes the patient's condition as having 'Multiple (rashes, macula)', initially localized to hands and later appearing on the face, becoming 'more widespread over time'. The question asks 'How many skin lesions are there?'. While the image shows two lesions, the clinical context indicates a broader picture of the patient's condition with multiple lesions overall. The options provided are 'single', 'multiple', and 'Not mentioned'. Since the image shows more than one lesion (two) and the clinical context states 'Multiple', the most accurate answer within the given options is 'multiple'. The majority of the successful model predictions also align with 'multiple'.\", 'answer': 'multiple', 'validated_answer': 'multiple'}\n",
      "Processing question 9/9: CQID036\n",
      "Applying reasoning layer for ENC00852, CQID036\n",
      "question_text:  What is the skin lesion texture?\n",
      "options:  ['smooth', 'rough', 'Not mentioned']\n",
      "question_type:  Texture\n",
      "model_predictions:  {'gemma-3-12b-it': {'combined_prediction': 'rough', 'unique_predictions': ['rough'], 'all_raw_predictions': ['rough', ''], 'all_sorted_predictions': [('rough', 1), ('', 1)]}, 'Qwen2-VL-7B-Instruct': {'combined_prediction': 'not mentioned', 'unique_predictions': ['not mentioned'], 'all_raw_predictions': ['Not mentioned', 'Not mentioned'], 'all_sorted_predictions': [('not mentioned', 2)]}, 'Qwen2-VL-2B-Instruct': {'combined_prediction': 'smooth', 'unique_predictions': ['smooth'], 'all_raw_predictions': ['smooth', 'Not mentioned'], 'all_sorted_predictions': [('smooth', 1), ('not mentioned', 1)]}, 'gemma-3-4b-it': {'combined_prediction': 'rough', 'unique_predictions': ['rough'], 'all_raw_predictions': ['rough', 'rough'], 'all_sorted_predictions': [('rough', 2)]}, 'Llama-3.2-11B-Vision-Instruct': {'combined_prediction': 'rough', 'unique_predictions': ['rough'], 'all_raw_predictions': ['Not mentioned', 'smooth', 'rough'], 'all_sorted_predictions': [('not mentioned', 1), ('smooth', 1), ('rough', 1)]}, 'Qwen2.5-VL-7B-Instruct': {'combined_prediction': 'smooth', 'unique_predictions': ['smooth'], 'all_raw_predictions': ['smooth', 'smooth'], 'all_sorted_predictions': [('smooth', 2)]}, 'Qwen2.5-VL-3B-Instruct': {'combined_prediction': 'smooth', 'unique_predictions': ['smooth'], 'all_raw_predictions': ['smooth', 'Not mentioned'], 'all_sorted_predictions': [('smooth', 1), ('not mentioned', 1)]}}\n",
      "- gemma-3-12b-it: rough\n",
      "- Qwen2-VL-7B-Instruct: not mentioned\n",
      "- Qwen2-VL-2B-Instruct: smooth\n",
      "- gemma-3-4b-it: rough\n",
      "- Llama-3.2-11B-Vision-Instruct: rough\n",
      "- Qwen2.5-VL-7B-Instruct: smooth\n",
      "- Qwen2.5-VL-3B-Instruct: smooth\n",
      "\n",
      "prompt: You are a medical expert analyzing dermatological images. Use the provided evidence to determine the most accurate answer(s) for the following question:\n",
      "\n",
      "    QUESTION: What is the skin lesion texture?\n",
      "    QUESTION TYPE: Texture\n",
      "    OPTIONS: smooth, rough, Not mentioned\n",
      "\n",
      "    IMAGE ANALYSIS:\n",
      "    {\n",
      "  \"SIZE\": \"Two distinct lesions are visible on the hand, each approximately 5-10 mm in longest dimension, similar in size and smaller than a thumbnail. No other distinct lesions of measurable size are apparent in the second image.\",\n",
      "  \"SITE_LOCATION\": \"Lesions are located on the dorsum of the hand. The second image shows general skin texture from an unidentifiable anatomical location.\",\n",
      "  \"SKIN_DESCRIPTION\": \"The lesions on the hand are macular, flat relative to surrounding skin, with a smooth surface and relatively well-defined but irregular boundaries. No scales or crust are noted on the lesions. The skin texture shown in the second image exhibits fine lines and appears generally smooth with no distinct lesions.\",\n",
      "  \"LESION_COLOR\": \"The lesions on the hand are hypopigmented (lighter than surrounding skin), appearing whitish or pale pinkish-white compared to the surrounding tan skin. No significant color variations within the lesions are observed. The skin in the second image shows a fair tone with pinkish-red hints but no distinct areas of abnormal color.\",\n",
      "  \"LESION_COUNT\": \"Two distinct hypopigmented lesions are visible on the dorsum of the hand. No other distinct lesions are identified in the second image.\",\n",
      "  \"EXTENT\": \"The lesions are localized to the visible area on the dorsum of the hand, affecting approximately 2-3% of the visible skin surface in that image. The full extent on the hand or body cannot be determined from either image.\",\n",
      "  \"TEXTURE\": \"The lesions appear smooth, similar to the texture of the surrounding unaffected skin in the first image. The skin texture in the second image shows fine lines and appears generally smooth, without scales or crust.\",\n",
      "  \"ONSET_INDICATORS\": \"The hypopigmentation of the lesions on the hand suggests a potentially chronic process; lack of erythema or crusting further supports a non-acute presentation. The second image provides no specific indicators of onset or chronicity.\",\n",
      "  \"ITCH_INDICATORS\": \"No visible excoriations, scratch marks, or signs of trauma are present on the lesions or in the skin area shown in the second image. Pruritus cannot be determined from images alone.\",\n",
      "  \"OVERALL_IMPRESSION\": \"Review of the images reveals two non-inflamed, well-demarcated hypopigmented macules on the dorsum of the hand. The second image shows unremarkable skin texture elsewhere. Potential diagnoses for the hypopigmentation include localized vitiligo, post-inflammatory hypopigmentation, or idiopathic guttate hypomelanosis. Clinical correlation and further examination are required.\"\n",
      "}\n",
      "\n",
      "    CLINICAL CONTEXT:\n",
      "    ```json\n",
      "{\n",
      "  \"DEMOGRAPHICS\": {\n",
      "    \"Age\": \"Approx. 50 years\",\n",
      "    \"Sex\": \"Female\",\n",
      "    \"Other\": \"Middle age\"\n",
      "  },\n",
      "  \"SITE_LOCATION\": [\n",
      "    \"Back of the hand\",\n",
      "    \"Face\"\n",
      "  ],\n",
      "  \"SKIN_DESCRIPTION\": [\n",
      "    \"Dark red rashes\",\n",
      "    \"Rashes gradually turn into Leukoplakia (whitish/hypopigmented patches)\",\n",
      "    \"Rashes become reddish on rubbing locally\",\n",
      "    \"Rashes getting bigger\",\n",
      "    \"Macula (flat spots) on the face\",\n",
      "    \"Face macula without skin scales\"\n",
      "  ],\n",
      "  \"LESION_COLOR\": [\n",
      "    \"Dark red\",\n",
      "    \"Reddish on rubbing\",\n",
      "    \"Turn into Leukoplakia (implying white/whitish)\",\n",
      "    \"Light red (on face)\"\n",
      "  ],\n",
      "  \"LESION_COUNT\": \"Multiple (rashes, macula)\",\n",
      "  \"EXTENT\": \"Localized to hands initially, later appearing on the face; becoming more widespread over time.\",\n",
      "  \"TEXTURE\": \"Without skin scales (on face macula). Not specified for hand lesions.\",\n",
      "  \"ONSET_INDICATORS\": \"Symptoms are getting worse, rashes are getting bigger, macula appeared on face one month later.\",\n",
      "  \"ITCH_INDICATORS\": \"None mentioned (Patient feels no specific symptoms).\",\n",
      "  \"OTHER_SYMPTOMS\": \"Problem mentally (details not specified).\",\n",
      "  \"TRIGGERS\": \"Rubbing locally causes lesions to become reddish.\",\n",
      "  \"HISTORY\": \"Received treatment based on diagnoses of eczema and Vitiligo. Refused pathological examination.\",\n",
      "  \"DIAGNOSTIC_CONSIDERATIONS\": [\n",
      "    \"Vitiligo (queried by patient, basis for treatment)\",\n",
      "    \"Eczema (basis for treatment)\",\n",
      "    \"Leukoplakia (term used to describe skin appearance change)\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "    MODEL PREDICTIONS:\n",
      "    - gemma-3-12b-it: rough\n",
      "- Qwen2-VL-7B-Instruct: not mentioned\n",
      "- Qwen2-VL-2B-Instruct: smooth\n",
      "- gemma-3-4b-it: rough\n",
      "- Llama-3.2-11B-Vision-Instruct: rough\n",
      "- Qwen2.5-VL-7B-Instruct: smooth\n",
      "- Qwen2.5-VL-3B-Instruct: smooth\n",
      "\n",
      "\n",
      "    Based on all the evidence above, determine the most accurate answer(s) to the question. Your task is to:\n",
      "    1. Analyze the evidence from the image analysis and clinical context\n",
      "    2. Consider the model predictions, noting any consensus or disagreement\n",
      "    3. Provide a brief reasoning for your conclusion\n",
      "    4. Select the final answer(s) from the available options\n",
      "\n",
      "    If selecting multiple answers is appropriate, provide them in a comma-separated list. If no answer can be determined, select \"Not mentioned\".\n",
      "\n",
      "    Format your response as a JSON object with these fields:\n",
      "    1. \"reasoning\": Your step-by-step reasoning process\n",
      "    2. \"answer\": Your final answer(s) as a single string or comma-separated list of options\n",
      "\n",
      "    When providing your answer, strictly adhere to the available options and only select from them.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_text:  ```json\n",
      "{\n",
      "  \"reasoning\": \"The question asks about the skin lesion texture based on the provided evidence. The IMAGE ANALYSIS section, which describes the lesions visible in the images, explicitly states under 'SKIN_DESCRIPTION' that the lesions on the hand have a 'smooth surface' and that 'No scales or crust are noted'. It also explicitly states under 'TEXTURE' that 'The lesions appear smooth, similar to the texture of the surrounding unaffected skin'. The clinical context mentions that the texture is 'Not specified for hand lesions' but notes the absence of skin scales on face macula. Since the images show the lesions on the hand, the description from the IMAGE ANALYSIS is the most relevant and direct evidence for the texture of the depicted lesions. This evidence clearly indicates the texture is smooth. The models' predictions are split, but the detailed description in the image analysis strongly supports 'smooth'.\",\n",
      "  \"answer\": \"smooth\"\n",
      "}\n",
      "```\n",
      "cleaned_text:  \n",
      "{\n",
      "  \"reasoning\": \"The question asks about the skin lesion texture based on the provided evidence. The IMAGE ANALYSIS section, which describes the lesions visible in the images, explicitly states under 'SKIN_DESCRIPTION' that the lesions on the hand have a 'smooth surface' and that 'No scales or crust are noted'. It also explicitly states under 'TEXTURE' that 'The lesions appear smooth, similar to the texture of the surrounding unaffected skin'. The clinical context mentions that the texture is 'Not specified for hand lesions' but notes the absence of skin scales on face macula. Since the images show the lesions on the hand, the description from the IMAGE ANALYSIS is the most relevant and direct evidence for the texture of the depicted lesions. This evidence clearly indicates the texture is smooth. The models' predictions are split, but the detailed description in the image analysis strongly supports 'smooth'.\",\n",
      "  \"answer\": \"smooth\"\n",
      "}\n",
      "\n",
      "Successfully parsed reasoning for ENC00852, CQID036\n",
      "reasoning_result:  {'reasoning': \"The question asks about the skin lesion texture based on the provided evidence. The IMAGE ANALYSIS section, which describes the lesions visible in the images, explicitly states under 'SKIN_DESCRIPTION' that the lesions on the hand have a 'smooth surface' and that 'No scales or crust are noted'. It also explicitly states under 'TEXTURE' that 'The lesions appear smooth, similar to the texture of the surrounding unaffected skin'. The clinical context mentions that the texture is 'Not specified for hand lesions' but notes the absence of skin scales on face macula. Since the images show the lesions on the hand, the description from the IMAGE ANALYSIS is the most relevant and direct evidence for the texture of the depicted lesions. This evidence clearly indicates the texture is smooth. The models' predictions are split, but the detailed description in the image analysis strongly supports 'smooth'.\", 'answer': 'smooth'}\n",
      "answer:  smooth\n",
      "reasoning_result:  {'reasoning': \"The question asks about the skin lesion texture based on the provided evidence. The IMAGE ANALYSIS section, which describes the lesions visible in the images, explicitly states under 'SKIN_DESCRIPTION' that the lesions on the hand have a 'smooth surface' and that 'No scales or crust are noted'. It also explicitly states under 'TEXTURE' that 'The lesions appear smooth, similar to the texture of the surrounding unaffected skin'. The clinical context mentions that the texture is 'Not specified for hand lesions' but notes the absence of skin scales on face macula. Since the images show the lesions on the hand, the description from the IMAGE ANALYSIS is the most relevant and direct evidence for the texture of the depicted lesions. This evidence clearly indicates the texture is smooth. The models' predictions are split, but the detailed description in the image analysis strongly supports 'smooth'.\", 'answer': 'smooth', 'validated_answer': 'smooth'}\n",
      "Processed all 9 questions for encounter ENC00852\n",
      "Formatted predictions saved to /storage/scratch1/2/kthakrar3/mediqa-magic-v2/outputs/outputs-akshay-2/outputs/data_cvqa_sys_reasoned_ENC00852_20250429_211045.json (1 complete encounters)\n"
     ]
    }
   ],
   "source": [
    "# Process a single encounter\n",
    "encounter_id = \"ENC00852\"  # Example encounter ID\n",
    "encounter_results = process_single_encounter_with_reasoning(agentic_data, encounter_id)\n",
    "\n",
    "# Format the results for evaluation (optional)\n",
    "formatted_predictions = format_reasoning_results_for_eval(\n",
    "    encounter_results,\n",
    "    os.path.join(output_dir, f\"data_cvqa_sys_reasoned_{encounter_id}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "289f98c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'encounter_id': 'ENC00852',\n",
       "  'CQID010-001': 2,\n",
       "  'CQID011-001': 0,\n",
       "  'CQID011-002': 2,\n",
       "  'CQID011-003': 7,\n",
       "  'CQID011-004': 7,\n",
       "  'CQID011-005': 7,\n",
       "  'CQID011-006': 7,\n",
       "  'CQID012-001': 2,\n",
       "  'CQID012-002': 3,\n",
       "  'CQID012-003': 3,\n",
       "  'CQID012-004': 3,\n",
       "  'CQID012-005': 3,\n",
       "  'CQID012-006': 3,\n",
       "  'CQID015-001': 3,\n",
       "  'CQID020-001': 1,\n",
       "  'CQID020-002': 9,\n",
       "  'CQID020-003': 9,\n",
       "  'CQID020-004': 9,\n",
       "  'CQID020-005': 9,\n",
       "  'CQID020-006': 9,\n",
       "  'CQID020-007': 9,\n",
       "  'CQID020-008': 9,\n",
       "  'CQID020-009': 9,\n",
       "  'CQID025-001': 1,\n",
       "  'CQID034-001': 7,\n",
       "  'CQID035-001': 1,\n",
       "  'CQID036-001': 0}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5feda",
   "metadata": {},
   "source": [
    "Reframe questions + their meanings\n",
    "Define options more clearly\n",
    "See if removing clinical context helps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
