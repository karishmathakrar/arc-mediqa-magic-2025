2025-04-11 22:15:20,730 - utils - INFO - Python version: 3.10.10 (main, Apr 15 2024, 11:52:16) [GCC 11.4.1 20230605 (Red Hat 11.4.1-2)]
2025-04-11 22:15:20,731 - utils - INFO - Python version info: sys.version_info(major=3, minor=10, micro=10, releaselevel='final', serial=0)
2025-04-11 22:15:20,731 - utils - INFO - PyTorch version: 2.6.0+cu124
2025-04-11 22:15:21,128 - utils - INFO - CUDA available: True
2025-04-11 22:15:21,128 - utils - INFO - CUDA version: 12.4
2025-04-11 22:15:21,155 - utils - INFO - CUDA device count: 1
2025-04-11 22:15:21,162 - utils - INFO - Current CUDA device: 0
2025-04-11 22:15:21,162 - utils - INFO - CUDA device name: NVIDIA H100 80GB HBM3
2025-04-11 22:15:21,246 - utils - INFO - GPU memory cleared
2025-04-11 22:15:21,246 - __main__ - INFO - Processing data from 2025_dataset/train to processed_data_inference
2025-04-11 22:15:21,246 - __main__ - INFO - Removing existing processed data from processed_data_inference
2025-04-11 22:15:21,248 - utils - INFO - Created directory: processed_data_inference
Processing batch 0:   0%|                                                                           | 0/1 [00:00<?, ?it/s]Processing batch 0: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]Processing batch 0: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]
2025-04-11 22:15:22,274 - data.processor - INFO - Processed 27 examples after batch 1
2025-04-11 22:15:22,274 - __main__ - INFO - Processed 27 examples
2025-04-11 22:15:22,276 - models.model_utils - INFO - Loading processor for model: merged_model
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
2025-04-11 22:15:24,891 - models.model_utils - INFO - Loading model for inference: merged_model
2025-04-11 22:15:26,693 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|                                                                    | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|██████████                                                  | 1/6 [00:01<00:05,  1.03s/it]Loading checkpoint shards:  33%|████████████████████                                        | 2/6 [00:02<00:04,  1.15s/it]Loading checkpoint shards:  50%|██████████████████████████████                              | 3/6 [00:03<00:04,  1.41s/it]Loading checkpoint shards:  67%|████████████████████████████████████████                    | 4/6 [00:05<00:03,  1.52s/it]Loading checkpoint shards:  83%|██████████████████████████████████████████████████          | 5/6 [00:07<00:01,  1.53s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████| 6/6 [00:07<00:00,  1.24s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████| 6/6 [00:07<00:00,  1.32s/it]
2025-04-11 22:15:34,884 - models.model_utils - INFO - Resizing token embeddings to match processor
2025-04-11 22:15:34,921 - data.loader - INFO - Loaded 27 examples from processed_data_inference
2025-04-11 22:15:34,922 - __main__ - INFO - Dataset size: 27
Running inference:   0%|                                                                           | 0/27 [00:00<?, ?it/s]/storage/coda1/p-dsgt_clef2025/0/kthakrar3/mediqa-magic-v2/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/storage/coda1/p-dsgt_clef2025/0/kthakrar3/mediqa-magic-v2/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/storage/coda1/p-dsgt_clef2025/0/kthakrar3/mediqa-magic-v2/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:651: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `64` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Running inference:   4%|██▍                                                                | 1/27 [00:07<03:23,  7.81s/it]Running inference:   7%|████▉                                                              | 2/27 [00:13<02:39,  6.39s/it]Running inference:  11%|███████▍                                                           | 3/27 [00:18<02:22,  5.93s/it]Running inference:  15%|█████████▉                                                         | 4/27 [00:23<02:11,  5.71s/it]Running inference:  19%|████████████▍                                                      | 5/27 [00:29<02:02,  5.57s/it]Running inference:  22%|██████████████▉                                                    | 6/27 [00:34<01:56,  5.53s/it]Running inference:  26%|█████████████████▎                                                 | 7/27 [00:40<01:50,  5.50s/it]Running inference:  30%|███████████████████▊                                               | 8/27 [00:45<01:45,  5.54s/it]Running inference:  33%|██████████████████████▎                                            | 9/27 [00:51<01:39,  5.50s/it]Running inference:  37%|████████████████████████▍                                         | 10/27 [00:56<01:32,  5.45s/it]Running inference:  41%|██████████████████████████▉                                       | 11/27 [01:01<01:26,  5.42s/it]Running inference:  44%|█████████████████████████████▎                                    | 12/27 [01:07<01:20,  5.40s/it]Running inference:  48%|███████████████████████████████▊                                  | 13/27 [01:12<01:15,  5.39s/it]Running inference:  52%|██████████████████████████████████▏                               | 14/27 [01:18<01:10,  5.43s/it]Running inference:  56%|████████████████████████████████████▋                             | 15/27 [01:23<01:05,  5.45s/it]Running inference:  59%|███████████████████████████████████████                           | 16/27 [01:29<00:59,  5.42s/it]Running inference:  63%|█████████████████████████████████████████▌                        | 17/27 [01:34<00:53,  5.40s/it]Running inference:  67%|████████████████████████████████████████████                      | 18/27 [01:39<00:48,  5.38s/it]Running inference:  70%|██████████████████████████████████████████████▍                   | 19/27 [01:45<00:43,  5.38s/it]Running inference:  74%|████████████████████████████████████████████████▉                 | 20/27 [01:50<00:37,  5.40s/it]Running inference:  78%|███████████████████████████████████████████████████▎              | 21/27 [01:55<00:32,  5.41s/it]Running inference:  81%|█████████████████████████████████████████████████████▊            | 22/27 [02:01<00:26,  5.39s/it]Running inference:  85%|████████████████████████████████████████████████████████▏         | 23/27 [02:06<00:21,  5.38s/it]Running inference:  89%|██████████████████████████████████████████████████████████▋       | 24/27 [02:12<00:16,  5.37s/it]Running inference:  93%|█████████████████████████████████████████████████████████████     | 25/27 [02:17<00:10,  5.41s/it]Running inference:  96%|███████████████████████████████████████████████████████████████▌  | 26/27 [02:22<00:05,  5.42s/it]Running inference: 100%|██████████████████████████████████████████████████████████████████| 27/27 [02:28<00:00,  5.41s/it]Running inference: 100%|██████████████████████████████████████████████████████████████████| 27/27 [02:28<00:00,  5.49s/it]
2025-04-11 22:18:03,462 - __main__ - INFO - 
Inference Results:
2025-04-11 22:18:03,463 - __main__ - INFO - Total examples processed: 27
2025-04-11 22:18:03,530 - __main__ - INFO - CSV results saved to 'evaluation_results/inference_results_finetuned.csv'
2025-04-11 22:18:03,530 - convert_results - INFO - Reading results from evaluation_results/inference_results_finetuned.csv
2025-04-11 22:18:04,026 - convert_results - INFO - Saving converted results to evaluation_results/data_cvqa_sys_finetuned.json
2025-04-11 22:18:04,028 - convert_results - INFO - Conversion complete. Processed 1 encounters.
2025-04-11 22:18:04,028 - __main__ - INFO - JSON results for evaluation saved to 'evaluation_results/data_cvqa_sys_finetuned.json'
2025-04-11 22:18:04,028 - postprocess_utils - INFO - Reading results from evaluation_results/inference_results_finetuned.csv
2025-04-11 22:18:04,030 - postprocess_utils - WARNING - No matching option found for CQID010: 'model'
2025-04-11 22:18:04,030 - postprocess_utils - WARNING - No matching option found for CQID011: 'model'
2025-04-11 22:18:04,030 - postprocess_utils - WARNING - No matching option found for CQID011: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID011: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID011: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID011: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID011: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID012: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID012: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID012: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID012: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID012: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID012: 'model'
2025-04-11 22:18:04,031 - postprocess_utils - WARNING - No matching option found for CQID015: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID020: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID025: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID034: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID035: 'model'
2025-04-11 22:18:04,032 - postprocess_utils - WARNING - No matching option found for CQID036: 'model'
2025-04-11 22:18:04,033 - postprocess_utils - INFO - Saving indexed results to evaluation_results/data_cvqa_sys_indices_finetuned.json
2025-04-11 22:18:04,034 - postprocess_utils - INFO - Conversion complete. Processed 1 encounters.
2025-04-11 22:18:04,034 - __main__ - INFO - Indexed JSON results for evaluation saved to 'evaluation_results/data_cvqa_sys_indices_finetuned.json'
2025-04-11 22:18:04,034 - __main__ - INFO - Inference completed successfully.
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
DEBUG - Processing text: system
You are a medical image analysis assistant. Your only task is to examine the provided clinica...
DEBUG - Split into 17 lines
DEBUG - Last 5 lines: ['', '', '', '', 'model']
DEBUG - Found 'model' in line: model
DEBUG - Returning last non-empty line: model
